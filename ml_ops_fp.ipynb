{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ml_ops_final_project\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Install dependencies"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "%pip install -r requirements.txt",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Startup cells"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Set environment variables for sagemaker_studio imports\n\nimport os\nos.environ['DataZoneProjectId'] = '42ncu6rss5uysp'\nos.environ['DataZoneDomainId'] = 'dzd-6uyj379iwy08h5'\nos.environ['DataZoneEnvironmentId'] = 'dm96g4uwtr0xwp'\nos.environ['DataZoneDomainRegion'] = 'us-east-2'\n\n# create both a function and variable for metadata access\n_resource_metadata = None\n\ndef _get_resource_metadata():\n    global _resource_metadata\n    if _resource_metadata is None:\n        _resource_metadata = {\n            \"AdditionalMetadata\": {\n                \"DataZoneProjectId\": \"42ncu6rss5uysp\",\n                \"DataZoneDomainId\": \"dzd-6uyj379iwy08h5\",\n                \"DataZoneEnvironmentId\": \"dm96g4uwtr0xwp\",\n                \"DataZoneDomainRegion\": \"us-east-2\",\n            }\n        }\n    return _resource_metadata\nmetadata = _get_resource_metadata()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\"\"\"\nLogging Configuration\n\nPurpose:\n--------\nThis sets up the logging framework for code executed in the user namespace.\n\"\"\"\n\nfrom typing import Optional\n\n\ndef _set_logging(log_dir: str, log_file: str, log_name: Optional[str] = None):\n    import os\n    import logging\n    from logging.handlers import RotatingFileHandler\n\n    level = logging.INFO\n    max_bytes = 5 * 1024 * 1024\n    backup_count = 5\n\n    # fallback to /tmp dir on access, helpful for local dev setup\n    try:\n        os.makedirs(log_dir, exist_ok=True)\n    except Exception:\n        log_dir = \"/tmp/kernels/\"\n\n    os.makedirs(log_dir, exist_ok=True)\n    log_path = os.path.join(log_dir, log_file)\n\n    logger = logging.getLogger() if not log_name else logging.getLogger(log_name)\n    logger.handlers = []\n    logger.setLevel(level)\n\n    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n\n    # Rotating file handler\n    fh = RotatingFileHandler(filename=log_path, maxBytes=max_bytes, backupCount=backup_count, encoding=\"utf-8\")\n    fh.setFormatter(formatter)\n    logger.addHandler(fh)\n\n    logger.info(f\"Logging initialized for {log_name}.\")\n\n\n_set_logging(\"/var/log/computeEnvironments/kernel/\", \"kernel.log\")\n_set_logging(\"/var/log/studio/data-notebook-kernel-server/\", \"metrics.log\", \"metrics\")",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import logging\nfrom sagemaker_studio import ClientConfig, sqlutils, sparkutils, dataframeutils\n\nlogger = logging.getLogger(__name__)\nlogger.info(\"Initializing sparkutils\")\nspark = sparkutils.init()\nlogger.info(\"Finished initializing sparkutils\")",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def _reset_os_path():\n    \"\"\"\n    Reset the process's working directory to handle mount timing issues.\n    \n    This function resolves a race condition where the Python process starts\n    before the filesystem mount is complete, causing the process to reference\n    old mount paths and inodes. By explicitly changing to the mounted directory\n    (/home/sagemaker-user), we ensure the process uses the correct, up-to-date\n    mount point.\n    \n    The function logs stat information (device ID and inode) before and after\n    the directory change to verify that the working directory is properly\n    updated to reference the new mount.\n    \n    Note:\n        This is executed at module import time to ensure the fix is applied\n        as early as possible in the kernel initialization process.\n    \"\"\"\n    try:\n        import os\n        import logging\n\n        logger = logging.getLogger(__name__)\n        logger.info(\"---------Before------\")\n        logger.info(\"CWD: %s\", os.getcwd())\n        logger.info(\"stat('.'): %s %s\", os.stat('.').st_dev, os.stat('.').st_ino)\n        logger.info(\"stat('/home/sagemaker-user'): %s %s\", os.stat('/home/sagemaker-user').st_dev, os.stat('/home/sagemaker-user').st_ino)\n\n        os.chdir(\"/home/sagemaker-user\")\n\n        logger.info(\"---------After------\")\n        logger.info(\"CWD: %s\", os.getcwd())\n        logger.info(\"stat('.'): %s %s\", os.stat('.').st_dev, os.stat('.').st_ino)\n        logger.info(\"stat('/home/sagemaker-user'): %s %s\", os.stat('/home/sagemaker-user').st_dev, os.stat('/home/sagemaker-user').st_ino)\n    except Exception as e:\n        logger.exception(f\"Failed to reset working directory: {e}\")\n\n_reset_os_path()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Notebook"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# **Machine Learning Operations Final Project**\nGroup Members:\n- **Bradley Stoller**\n- **Samuel Martinez Koss**\n- **Xigang Zhang**\n- **Zhiwei Guo**"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **General Notebook Configurations**"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "RANDOM_SEED = 42\n\nprint('General configuration complete')",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "General configuration complete\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **AWS Configurations**\nAWS setup: credentials, S3 buckets, IAM roles, and service clients"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# AWS Credentials\nAWS_ACCESS_KEY = 'REMOVEDRWIMQ423ZX2EREMOVED'\nAWS_SECRET_KEY = 'REMOVED5KRZgS8+oMPZCbNm3/0yBs0BwFlbx1yHREMOVED'\n\n# S3 Configuration\nBUCKET_NAME = 'ml-ops-fp'\nPREFIX = 'pokemon-classification'\n\n# IAM Role\nROLE = 'REMOVED84002890:role/service-role/AmazonSageMaker-ExecutionRole-20241120TREMOVED'\nROLE_ARN = 'arn:aws:iam::116527261367:role/SageMakerExecutionRole'\n\n# Initialize SageMaker Session and Boto3 Clients\nimport sagemaker\nimport boto3\n\nSESSION = sagemaker.Session()\nREGION = SESSION.boto_region_name\n\nSM_CLIENT = boto3.client('sagemaker')\nS3_CLIENT = boto3.client('s3')\n\nprint(f\"AWS Configuration loaded\")\nprint(f\"- Region: {REGION}\")\nprint(f\"- Bucket: {BUCKET_NAME}\")\nprint(f\"- Role ARN: {ROLE_ARN}\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Fetched defaults config from location: /etc/xdg/sagemaker/config.yaml\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "AWS Configuration loaded\n- Region: us-east-2\n- Bucket: ml-ops-fp\n- Role ARN: arn:aws:iam::116527261367:role/SageMakerExecutionRole\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **Import Library**"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Install Non-Default Sagemaker Studio Packages\n- `imbalanced-learn`\n- `mlflow`\n- `statsmodels`\n- `evidently`"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Install import libraries\nimport subprocess\nimport sys\n\n# Install imbalanced-learn, mlflow, statsmodels, and evidently\nsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"imbalanced-learn\"])\nsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"mlflow\"])\nsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"statsmodels\"])\nsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"evidently\"])\n\nprint(\"All packages installed\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "All packages installed\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Import all necessary packages"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Core Libraries\nimport pandas as pd\nimport numpy as np\nimport json\nimport time\nimport joblib\nimport tarfile\nimport warnings\nfrom io import StringIO\nfrom collections import Counter\nfrom itertools import product\nimport os\n\n# Data Processing & ML\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.utils.class_weight import compute_sample_weight\nfrom sklearn.metrics import (\n    classification_report, confusion_matrix, roc_curve, auc,\n    precision_recall_curve, accuracy_score, precision_score,\n    recall_score, f1_score\n)\n\n# Imbalanced Learning\nfrom imblearn.over_sampling import SMOTE\n\n# Statistical Analysis\nimport scipy.stats as stats\nfrom scipy.stats import randint, uniform\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# XGBoost\nimport xgboost as xgb\n\n# MLflow\nimport mlflow\nimport mlflow.sklearn\nfrom mlflow.models import infer_signature\n\n# SageMaker\nimport sagemaker\nimport boto3\nfrom sagemaker.automl.automl import AutoML\nfrom sagemaker.sklearn.model import SKLearnModel\nfrom sagemaker.xgboost import XGBoostModel\nfrom sagemaker.predictor import Predictor\nfrom sagemaker.serializers import CSVSerializer\nfrom sagemaker.deserializers import JSONDeserializer, CSVDeserializer\nfrom sagemaker.model_monitor import DefaultModelMonitor, MonitoringExecution\nfrom sagemaker.model_monitor.dataset_format import DatasetFormat\n\n# Evidently\nimport base64\nfrom evidently.legacy.test_suite import TestSuite\nfrom evidently.legacy.tests import TestNumberOfDriftedColumns\n\nwarnings.filterwarnings('ignore')\n\nprint(\"All libraries imported\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "All libraries imported\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **Function Library**"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def clean_data(data):\n    \"\"\"Clearn the data to be used for modeling. \"\"\"\n\n    # Copy data to avoid modifying original\n    data_copy = data.copy()\n\n    # Drop columns irrelevant to mega evolutions\n    data_copy = data_copy.drop(columns=[\n        'Name',\n        'Number',\n        'hasGender',\n        'Pr_Male',\n    ])\n\n    # Create binary indicators for optional secondary attributes\n    data_copy['Has_Type_2'] = data_copy['Type_2'].notna().astype(int)\n    data_copy['Has_Egg_Group_2'] = data_copy['Egg_Group_2'].notna().astype(int)\n\n    # Bin Catch_Rate into difficulty categories (higher rate = easier to catch)\n    data_copy['Catch_Difficulty'] = pd.cut(\n        data_copy['Catch_Rate'],\n        bins=3,\n        labels=['Hard', 'Medium', 'Easy']\n    ).astype(str)  # Convert to string immediately to avoid categorical issues\n\n    # Separate features and target (drop original Catch_Rate, keep binned version)\n    features = data_copy.drop(['Catch_Rate', 'hasMegaEvolution'], axis=1)\n    target = data_copy['hasMegaEvolution']\n\n    return features, target\n\ndef scale_and_encode(X_train, X_test):\n    \"\"\"Scale and encode the data for modeling. \"\"\"\n\n    # Identify integer colums that need conversion\n    num_cols = [\n        c for c in X_train.select_dtypes('integer').columns\n        if len(X_train[c].unique()) > 10\n    ]\n    X_train = X_train.astype({c: 'float32' for c in num_cols})\n    X_test = X_test.astype({c: 'float32' for c in num_cols})\n\n    # Standardize interval features\n    num_cols = X_train.select_dtypes(exclude=['bool', 'object', 'string', 'int64']).columns\n    for col in num_cols:\n        scaler = StandardScaler()\n        X_train[col] = scaler.fit_transform(X_train[[col]])\n        X_test[col] = scaler.transform(X_test[[col]])\n\n    # Encode categorical features using a label encoder\n    cat_cols = X_train.select_dtypes(include=['object', 'bool']).columns\n    for col in cat_cols:\n        X_train[col] = X_train[col].astype(str).replace('nan', 'missing')\n        X_test[col] = X_test[col].astype(str).replace('nan', 'missing')\n\n        le = LabelEncoder()\n        X_train[col] = le.fit_transform(X_train[col])\n\n        # Ensure that unseen columns are encoded as -1\n        test_x_col = []\n        for val in X_test[col]:\n            if val in le.classes_:\n                test_x_col.append(le.transform([val])[0])\n            else:\n                test_x_col.append(-1)\n        X_test[col] = test_x_col\n\n    return X_train, X_test\n\ndef prepare_data(data, verbose=False):\n    \"\"\"Clean the data, split the data, and apply SMOTE for modeling. \"\"\"\n\n    # Remove unnecessary cols, feature engineering\n    X, y = clean_data(data)\n\n    # Split data into train and test\n    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42, stratify= y\n    )\n\n    # Scale interval features and encode categorical features\n    X_train, X_test = scale_and_encode(X_train_raw, X_test_raw)\n\n    # Apply SMOTE to handle class imbalance\n    smote = SMOTE(random_state=42)\n    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n    if verbose:\n        # Check class distribution before SMOTE\n        print(\"\\nClass distribution before SMOTE:\")\n        print(Counter(y_train))\n\n        # Check class distribution after SMOTE\n        print(\"\\nClass distribution after SMOTE:\")\n        print(Counter(y_train_resampled))\n\n    return X_train_resampled, X_test, y_train_resampled, y_test, X_train, y_train\n\ndef log_model_metrics(y_actual, y_pred):\n    \"\"\"Setup logging configurations for MLflow usage. \"\"\"\n\n    mlflow.log_metric('accuracy', accuracy_score(y_actual, y_pred))\n    mlflow.log_metric('precision', precision_score(y_actual, y_pred))\n    mlflow.log_metric('recall', recall_score(y_actual, y_pred))\n    mlflow.log_metric('f1', f1_score(y_actual, y_pred))\n\ndef confusion_matrix_plot(y_actual, y_pred):\n    \"\"\"Plot a confusion matrix of the results for MLflow. \"\"\"\n\n    conf_matrix = confusion_matrix(y_actual, y_pred)\n    \n    fig, ax = plt.subplots(figsize=(8, 6))\n\n    # Use a color palette that clearly differentiates cells (custom or built-in)\n    cmap = sns.color_palette(\"RdYlBu_r\", as_cmap=True)\n\n    # Draw heatmap with square cells and no colorbar for cleaner look\n    sns.heatmap(\n        conf_matrix,\n        annot=True,\n        fmt='d',\n        cmap=cmap,\n        xticklabels=['No Mega', 'Has Mega'],\n        yticklabels=['No Mega', 'Has Mega'],\n        cbar=False,\n        square=True,\n        linewidths=1,\n        linecolor='gray',\n        ax=ax\n    )\n\n    ax.set_xlabel('Predicted', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Actual', fontsize=12, fontweight='bold')\n    ax.set_title('Mega Evolution Prediction Confusion Matrix', fontsize=14, pad=20)\n\n    # Add refined annotations inside cells - positions adjusted for better spacing\n    # Get bounding box coordinates of each cell for placement reference\n    for i in range(2):\n        for j in range(2):\n            text = \"\"\n            if i == 0 and j == 0:\n                text = 'True Negatives\\n(Correctly predicted\\nno Mega Evolution)'\n                xytext = (j + 0.5, i + 0.7)\n            elif i == 0 and j == 1:\n                text = 'False Positives\\n(Incorrectly predicted\\nMega Evolution)'\n                xytext = (j + 0.5, i + 0.7)\n            elif i == 1 and j == 0:\n                text = 'False Negatives\\n(Missed actual\\nMega Evolution)'\n                xytext = (j + 0.5, i + 0.7)\n            elif i == 1 and j == 1:\n                text = 'True Positives\\n(Correctly predicted\\nMega Evolution)'\n                xytext = (j + 0.5, i + 0.7)\n\n            ax.text(\n                xytext[0], xytext[1], text,\n                ha='center',\n                va='center',\n                fontsize=9,\n                color='black',\n                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.7)\n            )\n\n    fig.tight_layout()\n    return fig\n\ndef roc_curve_plot(y_actual, y_prob):\n    \"\"\"Plot a ROC Curve plot of the results for MLflow. \"\"\"\n\n    # Compute ROC curve and AUC\n    fpr, tpr, _ = roc_curve(y_actual, y_prob)\n    roc_auc = auc(fpr, tpr)\n\n    fig, ax = plt.subplots(figsize=(8, 6))\n    ax.plot(fpr, tpr, lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n    ax.plot([0, 1], [0, 1], lw=2, linestyle='--')\n\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.05])\n    ax.set_xlabel('False Positive Rate')\n    ax.set_ylabel('True Positive Rate')\n    ax.set_title('Receiver Operating Characteristic')\n\n    ax.legend(loc=\"lower right\")\n    return fig\n\ndef precision_recall_plot(y_actual, y_prob):\n    \"\"\"Plot a precision-recall plot of the results for MLflow. \"\"\"\n\n    # Compute precision-recall values\n    precision, recall, _ = precision_recall_curve(y_actual, y_prob)\n\n    fig, ax = plt.subplots(figsize=(8, 6))\n    ax.plot(recall, precision, lw=2)\n    ax.set_xlabel(\"Recall\")\n    ax.set_ylabel(\"Precision\")\n    ax.set_title(\"Precision-Recall Curve\")\n\n    return fig\n\ndef feature_importance_plot(model, features):    \n    \"\"\"Plot features importances for MLflow. \"\"\"\n\n    importances = model.feature_importances_\n    feature_importance_dict = {name: imp for name, imp in zip(features, importances)}\n    sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n\n    # Prepare top 10 features\n    top_n = min(10, len(sorted_features))\n    feature_names_plot = [name for name, _ in sorted_features[:top_n]]\n    importance_values = [imp for _, imp in sorted_features[:top_n]]\n\n    fig, ax = plt.subplots(figsize=(12, 8))\n    ax.set_title(\"Feature Importances\")\n\n    ax.barh(range(top_n), importance_values, align=\"center\")\n    ax.set_yticks(range(top_n))\n    ax.set_yticklabels(feature_names_plot)\n    ax.invert_yaxis()  # Highest importance at the top\n    ax.set_xlabel(\"Importance\")\n\n    fig.tight_layout()\n    return fig\n\ndef log_model_plots(y_actual, y_pred, y_prob, model, features):\n    \"\"\"Set up logging for plots used by MLflow. \"\"\"\n\n    fig = confusion_matrix_plot(y_actual, y_pred)\n    mlflow.log_figure(fig, 'confusion_matrix.png')\n    plt.close(fig)\n\n    fig = roc_curve_plot(y_actual, y_prob)\n    mlflow.log_figure(fig, 'roc_curve.png')\n    plt.close(fig)\n\n    fig = precision_recall_plot(y_actual, y_prob)\n    mlflow.log_figure(fig, 'precision_recall.png')\n    plt.close(fig)\n\n    fig = feature_importance_plot(model, features)\n    mlflow.log_figure(fig, 'feature_importance.png')\n    plt.close(fig)\n\ndef mlflow_pipeline(features, target, random_seed= RANDOM_SEED, run_name= 'test_run', experiment_name= 'Default', **model_params):\n    \"\"\"Create the MLflow experiment pipeline. \"\"\"\n\n    warnings.filterwarnings('ignore')\n    np.random.seed(random_seed)\n    mlflow.set_tracking_uri('file:./mlruns')\n    mlflow.set_experiment(experiment_name)\n\n    with mlflow.start_run(run_name=run_name):\n        gb_model = GradientBoostingClassifier(random_state=random_seed, **model_params)\n\n        gb_model.fit(features, target)\n        y_pred = gb_model.predict(features)\n        y_prob = gb_model.predict_proba(features)[:, 1]\n\n        mlflow.log_params(model_params)\n        log_model_metrics(target, y_pred)\n        log_model_plots(target, y_pred, y_prob, gb_model, features.columns)\n\n        signature = infer_signature(features, gb_model.predict(features))\n        mlflow.sklearn.log_model(\n            gb_model, name=run_name[:5], signature=signature\n        )\n\ndef sample_params(param_dist, n_samples=5, random_state=None):\n    \"\"\"Get the sample parameters for usage in MLflow. \"\"\"\n\n    rng = np.random.default_rng(random_state)\n    samples = []\n    for _ in range(n_samples):\n        sample = {}\n        for param, dist in param_dist.items():\n            if hasattr(dist, 'rvs'):\n                val = dist.rvs(random_state=rng)\n                if dist.dist.name == 'randint':\n                    val = int(val)\n                sample[param] = val\n            else:\n                sample[param] = rng.choice(dist)\n        samples.append(sample)\n    return samples\n\ndef detect_model_drift(test_data, y_pred, report_s3_key, predictor, baseline_data, bucket_name, s3_client):\n    \"\"\"Detect model drift by comparing test data predictions against baseline. \"\"\"\n\n    print(\"=\"*60)\n    print(\"MODEL MONITORING: DRIFT DETECTION\")\n    print(\"=\"*60)\n    \n    # Add predictions to the baseline data using the deployed model\n    print(\"Generating baseline predictions from the deployed model...\")\n    baseline_predictions = []\n\n    for i in range(len(baseline_data)):\n        sample = baseline_data.iloc[i:i+1].values\n        pred = predictor.predict(sample)\n        pred_value = float(np.array(pred).flatten()[0])\n        baseline_predictions.append(1 if pred_value > 0.5 else 0)\n    \n    baseline_with_predictions = baseline_data.copy()\n    baseline_with_predictions['prediction'] = baseline_predictions\n    \n    current_with_predictions = test_data.copy()\n    current_with_predictions['prediction'] = y_pred\n    \n    # Create Evidently AI test suite for drift detection\n    test_suite = TestSuite(tests=[\n        TestNumberOfDriftedColumns(lt=3),\n    ])\n    \n    # Run drift detection\n    test_suite.run(reference_data=baseline_with_predictions, current_data=current_with_predictions)\n    \n    # Get results\n    results = test_suite.as_dict()\n    \n    # Print the drift summary\n    print(\"\\nDrift Detection Results:\")\n    print(f\"Total features analyzed: {baseline_with_predictions.shape[1]}\")\n    \n    # Extract the test results\n    for test in results['tests']:\n        print(f\"\\nTest: {test['name']}\")\n        print(f\"Status: {test['status']}\")\n        if 'description' in test:\n            print(f\"Description: {test['description']}\")\n        if 'parameters' in test:\n            print(f\"Parameters: {test['parameters']}\")\n    \n    # Save the Drift Report\n    s3_client.put_object(\n        Bucket=bucket_name,\n        Key=report_s3_key,\n        Body=test_suite.get_html(),\n        ContentType='text/html'\n    )\n    \n    print(f\"\\nReport saved to s3://{bucket_name}/{report_s3_key}\")\n    \n    return results\n\ndef push_to_github(commit_message= \"Update ml_ops_final_project.ipynb\"):\n    \"\"\"Push notebook to GitHub. \"\"\"\n    \n    # Configure git\n    subprocess.run([\"git\", \"config\", \"--global\", \"user.email\", \"bhs.stoller@gmail.com\"])\n    subprocess.run([\"git\", \"config\", \"--global\", \"user.name\", \"Bradley Stoller\"])\n    \n    # Check if git repo exists, if not initialize\n    if not os.path.exists(\".git\"):\n        subprocess.run([\"git\", \"init\"])\n        REMOTE_URL = f\"https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{GITHUB_REPO}.git\"\n        subprocess.run([\"git\", \"remote\", \"add\", \"origin\", REMOTE_URL])\n    \n    # Add, commit, and push\n    subprocess.run([\"git\", \"add\", \".\"])\n    subprocess.run([\"git\", \"commit\", \"-m\", commit_message])\n    subprocess.run([\"git\", \"push\", \"-u\", \"origin\", BRANCH])\n    \n    print(f\"Notebook pushed to GitHub: https://github.com/{GITHUB_USERNAME}/{GITHUB_REPO}\")\n\n# Usage\npush_to_github(\"Updated model monitoring code\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "hint: Using 'master' as the name for the initial branch. This default branch name\nhint: is subject to change. To configure the initial branch name to use in all\nhint: of your new repositories, which will suppress this warning, call:\nhint: \nhint: \tgit config --global init.defaultBranch <name>\nhint: \nhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\nhint: 'development'. The just-created branch can be renamed via this command:\nhint: \nhint: \tgit branch -m <name>\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Initialized empty Git repository in /home/sagemaker-user/.git/\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "On branch master\n\nInitial commit\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\t.bashrc\n\t.cache/\n\t.gitconfig\n\t.ipython/\n\t.user_packages/\n\tbaseline_stats.json\n\tmlruns/\n\tmodel.tar.gz\n\tmonitoring_report_modified.html\n\tmonitoring_report_original.html\n\tpokemon_test.csv\n\tpokemon_train.csv\n\tsample_capture.jsonl\n\tsk_model/\n\txgboost-model\n\nnothing added to commit but untracked files present (use \"git add\" to track)\nNotebook pushed to GitHub: https://github.com/bhstoller/ml-ops-fp\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "error: '.user_packages/' does not have a commit checked out\nfatal: adding files failed\nerror: src refspec main does not match any\nerror: failed to push some refs to 'https://github.com/bhstoller/ml-ops-fp.git'\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **1. Choose a dataset that has an outcome (predictive) variable**\nFor our dataset, we chose to use a variety of information about pokemon characters, with the predictive variable being `hasMegaEvolution`."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "DATA_KEY = 'pokemon-data/pokemon.csv'\nS3_PATH = f's3://{BUCKET_NAME}/{DATA_KEY}'\ndf = pd.read_csv(S3_PATH)\nprint(f\"Dataset Shape: {df.shape}\\n\")\ndf.info()\ndf.head()",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset Shape: (721, 23)\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 721 entries, 0 to 720\nData columns (total 23 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   Number            721 non-null    int64  \n 1   Name              721 non-null    object \n 2   Type_1            721 non-null    object \n 3   Type_2            350 non-null    object \n 4   Total             721 non-null    int64  \n 5   HP                721 non-null    int64  \n 6   Attack            721 non-null    int64  \n 7   Defense           721 non-null    int64  \n 8   Sp_Atk            721 non-null    int64  \n 9   Sp_Def            721 non-null    int64  \n 10  Speed             721 non-null    int64  \n 11  Generation        721 non-null    int64  \n 12  isLegendary       721 non-null    bool   \n 13  Color             721 non-null    object \n 14  hasGender         721 non-null    bool   \n 15  Pr_Male           644 non-null    float64\n 16  Egg_Group_1       721 non-null    object \n 17  Egg_Group_2       191 non-null    object \n 18  hasMegaEvolution  721 non-null    bool   \n 19  Height_m          721 non-null    float64\n 20  Weight_kg         721 non-null    float64\n 21  Catch_Rate        721 non-null    int64  \n 22  Body_Style        721 non-null    object \ndtypes: bool(3), float64(3), int64(10), object(7)\nmemory usage: 114.9+ KB\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "   Number        Name Type_1  ... Weight_kg  Catch_Rate      Body_Style\n0       1   Bulbasaur  Grass  ...       6.9          45       quadruped\n1       2     Ivysaur  Grass  ...      13.0          45       quadruped\n2       3    Venusaur  Grass  ...     100.0          45       quadruped\n3       4  Charmander   Fire  ...       8.5          45  bipedal_tailed\n4       5  Charmeleon   Fire  ...      19.0          45  bipedal_tailed\n\n[5 rows x 23 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Number</th>\n      <th>Name</th>\n      <th>Type_1</th>\n      <th>Type_2</th>\n      <th>Total</th>\n      <th>HP</th>\n      <th>Attack</th>\n      <th>Defense</th>\n      <th>Sp_Atk</th>\n      <th>Sp_Def</th>\n      <th>Speed</th>\n      <th>Generation</th>\n      <th>isLegendary</th>\n      <th>Color</th>\n      <th>hasGender</th>\n      <th>Pr_Male</th>\n      <th>Egg_Group_1</th>\n      <th>Egg_Group_2</th>\n      <th>hasMegaEvolution</th>\n      <th>Height_m</th>\n      <th>Weight_kg</th>\n      <th>Catch_Rate</th>\n      <th>Body_Style</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Bulbasaur</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>318</td>\n      <td>45</td>\n      <td>49</td>\n      <td>49</td>\n      <td>65</td>\n      <td>65</td>\n      <td>45</td>\n      <td>1</td>\n      <td>False</td>\n      <td>Green</td>\n      <td>True</td>\n      <td>0.875</td>\n      <td>Monster</td>\n      <td>Grass</td>\n      <td>False</td>\n      <td>0.71</td>\n      <td>6.9</td>\n      <td>45</td>\n      <td>quadruped</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Ivysaur</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>405</td>\n      <td>60</td>\n      <td>62</td>\n      <td>63</td>\n      <td>80</td>\n      <td>80</td>\n      <td>60</td>\n      <td>1</td>\n      <td>False</td>\n      <td>Green</td>\n      <td>True</td>\n      <td>0.875</td>\n      <td>Monster</td>\n      <td>Grass</td>\n      <td>False</td>\n      <td>0.99</td>\n      <td>13.0</td>\n      <td>45</td>\n      <td>quadruped</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Venusaur</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>525</td>\n      <td>80</td>\n      <td>82</td>\n      <td>83</td>\n      <td>100</td>\n      <td>100</td>\n      <td>80</td>\n      <td>1</td>\n      <td>False</td>\n      <td>Green</td>\n      <td>True</td>\n      <td>0.875</td>\n      <td>Monster</td>\n      <td>Grass</td>\n      <td>True</td>\n      <td>2.01</td>\n      <td>100.0</td>\n      <td>45</td>\n      <td>quadruped</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Charmander</td>\n      <td>Fire</td>\n      <td>NaN</td>\n      <td>309</td>\n      <td>39</td>\n      <td>52</td>\n      <td>43</td>\n      <td>60</td>\n      <td>50</td>\n      <td>65</td>\n      <td>1</td>\n      <td>False</td>\n      <td>Red</td>\n      <td>True</td>\n      <td>0.875</td>\n      <td>Monster</td>\n      <td>Dragon</td>\n      <td>False</td>\n      <td>0.61</td>\n      <td>8.5</td>\n      <td>45</td>\n      <td>bipedal_tailed</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Charmeleon</td>\n      <td>Fire</td>\n      <td>NaN</td>\n      <td>405</td>\n      <td>58</td>\n      <td>64</td>\n      <td>58</td>\n      <td>80</td>\n      <td>65</td>\n      <td>80</td>\n      <td>1</td>\n      <td>False</td>\n      <td>Red</td>\n      <td>True</td>\n      <td>0.875</td>\n      <td>Monster</td>\n      <td>Dragon</td>\n      <td>False</td>\n      <td>1.09</td>\n      <td>19.0</td>\n      <td>45</td>\n      <td>bipedal_tailed</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "application/vnd.datanotebooks+parquet+snappy": {
              "data": "UEFSMRUEFVAVQEwVChUAEgAAKAQBAAkBAAIJBwQAAw0IPAQAAAAAAAAABQAAAAAAAAAVABUWFRosFQoVEBUGFQYcGAgFAAAAAAAAABgIAQAAAAAAAAAWACgIBQAAAAAAAAAYCAEAAAAAAAAAAAAACygCAAAACgEDA4hGABUEFYABFYABTBUKFQASAABATAkAAABCdWxiYXNhdXIHAAAASXZ5AQscCAAAAFZlbnUBDGwKAAAAQ2hhcm1hbmRlcgoAAABDaGFybWVsZW9uFQAVFhUaLBUKFRAVBhUGHDYAKAhWZW51c2F1chgJQnVsYmFzYXVyAAAACygCAAAACgEDA4hGABUEFSIVJkwVBBUAEgAAEUAFAAAAR3Jhc3MEAAAARmlyZRUAFRIVFiwVChUQFQYVBhw2ACgFR3Jhc3MYBEZpcmUAAAAJIAIAAAAKAQEDGBUEFRQVGEwVAhUAEgAACiQGAAAAUG9pc29uFQAVEhUWLBUKFRAVBhUGHDYEKAZQb2lzb24YBlBvaXNvbgAAAAkgAgAAAAMHAQYAFQQVQBU4TBUIFQASAAAgCD4BAAUBAJUNCDwNAgAAAAAAADUBAAAAAAAAFQAVFBUYLBUKFRAVBhUGHBgIDQIAAAAAAAAYCDUBAAAAAAAAFgAoCA0CAAAAAAAAGAg1AQAAAAAAAAAAAAokAgAAAAoBAgPkARUEFVAVQEwVChUAEgAAKAQtAAkBADwJBwQAUA0IPCcAAAAAAAAAOgAAAAAAAAAVABUWFRosFQoVEBUGFQYcGAhQAAAAAAAAABgIJwAAAAAAAAAWACgIUAAAAAAAAAAYCCcAAAAAAAAAAAAACygCAAAACgEDA4hGABUEFVAVQEwVChUAEgAAKAQxAAkBAD4JBwQAUg0IPDQAAAAAAAAAQAAAAAAAAAAVABUWFRosFQoVEBUGFQYcGAhSAAAAAAAAABgIMQAAAAAAAAAWACgIUgAAAAAAAAAYCDEAAAAAAAAAAAAACygCAAAACgEDA4hGABUEFVAVQEwVChUAEgAAKAQxAAkBAD8JBwQAUw0IPCsAAAAAAAAAOgAAAAAAAAAVABUWFRosFQoVEBUGFQYcGAhTAAAAAAAAABgIKwAAAAAAAAAWACgIUwAAAAAAAAAYCCsAAAAAAAAAAAAACygCAAAACgEDA4hGABUEFUAVOEwVCBUAEgAAIARBAAkBAFAJB0AAZAAAAAAAAAA8AAAAAAAAABUAFRQVGCwVChUQFQYVBhwYCGQAAAAAAAAAGAg8AAAAAAAAABYAKAhkAAAAAAAAABgIPAAAAAAAAAAAAAAKJAIAAAAKAQID5AEVBBVAFThMFQgVABIAACAEQQAJAQBQCQdAAGQAAAAAAAAAMgAAAAAAAAAVABUUFRgsFQoVEBUGFQYcGAhkAAAAAAAAABgIMgAAAAAAAAAWACgIZAAAAAAAAAAYCDIAAAAAAAAAAAAACiQCAAAACgECA+QAFQQVQBU4TBUIFQASAAAgBC0ACQEAPAkHQABQAAAAAAAAAEEAAAAAAAAAFQAVFBUYLBUKFRAVBhUGHBgIUAAAAAAAAAAYCC0AAAAAAAAAFgAoCFAAAAAAAAAAGAgtAAAAAAAAAAAAAAokAgAAAAoBAgPkAhUEFRAVFEwVAhUAEgAACBwBAAAAAAAAABUAFRIVFiwVChUQFQYVBhwYCAEAAAAAAAAAGAgBAAAAAAAAABYAKAgBAAAAAAAAABgIAQAAAAAAAAAAAAAJIAIAAAAKAQEKABUAFQ4VEiwVChUAFQYVBhwYAQAYAQAWACgBABgBAAAAAAcYAgAAAAoBABUEFSAVJEwVBBUAEgAAEDwFAAAAR3JlZW4DAAAAUmVkFQAVEhUWLBUKFRAVBhUGHDYAKANSZWQYBUdyZWVuAAAACSACAAAACgEBAxgVABUOFRIsFQoVABUGFQYcGAEBGAEBFgAoAQEYAQEAAAAHGAIAAAAKAR8VBBUQFRRMFQIVABIAAAgcAAAAAAAA7D8VABUSFRYsFQoVEBUGFQYcGAgAAAAAAADsPxgIAAAAAAAA7D8WACgIAAAAAAAA7D8YCAAAAAAAAOw/AAAACSACAAAACgEBCgAVBBUWFRpMFQIVABIAAAsoBwAAAE1vbnN0ZXIVABUSFRYsFQoVEBUGFQYcNgAoB01vbnN0ZXIYB01vbnN0ZXIAAAAJIAIAAAAKAQEKABUEFSYVKkwVBBUAEgAAE0gFAAAAR3Jhc3MGAAAARHJhZ29uFQAVEhUWLBUKFRAVBhUGHDYAKAVHcmFzcxgGRHJhZ29uAAAACSACAAAACgEBAxgVABUOFRIsFQoVABUGFQYcGAEBGAEAFgAoAQEYAQAAAAAHGAIAAAAKAQQVBBVQFU5MFQoVABIAAChAuB6F61G45j+uR+F6FK7vPxQFCQQAQAEWLB6F4z9xPQrXo3DxPxUAFRYVGiwVChUQFQYVBhwYCBSuR+F6FABAGAiF61G4HoXjPxYAKAgUrkfhehQAQBgIhetRuB6F4z8AAAALKAIAAAAKAQMDiEYAFQQVUBU+TBUKFQASAAAoBJqZAQEIG0AABQEAKg0IAFkNCCQhQAAAAAAAADNAFQAVFhUaLBUKFRAVBhUGHBgIAAAAAAAAWUAYCJqZmZmZmRtAFgAoCAAAAAAAAFlAGAiamZmZmZkbQAAAAAsoAgAAAAoBAwOIRgAVBBUQFRRMFQIVABIAAAgcLQAAAAAAAAAVABUSFRYsFQoVEBUGFQYcGAgtAAAAAAAAABgILQAAAAAAAAAWACgILQAAAAAAAAAYCC0AAAAAAAAAAAAACSACAAAACgEBCgAVBBU+FUJMFQQVABIAAB94CQAAAHF1YWRydXBlZA4AAABiaXBlZGFsX3RhaWxlZBUAFRIVFiwVChUQFQYVBhw2ACgJcXVhZHJ1cGVkGA5iaXBlZGFsX3RhaWxlZAAAAAkgAgAAAAoBAQMYFQQZ/Bg1ABgGc2NoZW1hFS4AFQQlAhgGTnVtYmVyABUMJQIYBE5hbWUlAEwcAAAAFQwlAhgGVHlwZV8xJQBMHAAAABUMJQIYBlR5cGVfMiUATBwAAAAVBCUCGAVUb3RhbAAVBCUCGAJIUAAVBCUCGAZBdHRhY2sAFQQlAhgHRGVmZW5zZQAVBCUCGAZTcF9BdGsAFQQlAhgGU3BfRGVmABUEJQIYBVNwZWVkABUEJQIYCkdlbmVyYXRpb24AFQAlAhgLaXNMZWdlbmRhcnkAFQwlAhgFQ29sb3IlAEwcAAAAFQAlAhgJaGFzR2VuZGVyABUKJQIYB1ByX01hbGUAFQwlAhgLRWdnX0dyb3VwXzElAEwcAAAAFQwlAhgLRWdnX0dyb3VwXzIlAEwcAAAAFQAlAhgQaGFzTWVnYUV2b2x1dGlvbgAVCiUCGAhIZWlnaHRfbQAVCiUCGAlXZWlnaHRfa2cAFQQlAhgKQ2F0Y2hfUmF0ZQAVDCUCGApCb2R5X1N0eWxlJQBMHAAAABYKGRwZ/BcmABwVBBk1AAYQGRgGTnVtYmVyFQIWChb8ARbwASZkJggcGAgFAAAAAAAAABgIAQAAAAAAAAAWACgIBQAAAAAAAAAYCAEAAAAAAAAAABksFQQVABUCABUAFRAVAgA8KQYZJgAKAAAAJgAcFQwZNQAGEBkYBE5hbWUVAhYKFooCFo4CJpgDJvgBHDYAKAhWZW51c2F1chgJQnVsYmFzYXVyABksFQQVABUCABUAFRAVAgA8FlgZBhkmAAoAAAAmABwVDBk1AAYQGRgGVHlwZV8xFQIWChaUARacASbIBCaGBBw2ACgFR3Jhc3MYBEZpcmUAGSwVBBUAFQIAFQAVEBUCADwWLhkGGSYACgAAACYAHBUMGTUABhAZGAZUeXBlXzIVAhYKFowBFpQBJtYFJqIFHDYEKAZQb2lzb24YBlBvaXNvbgAZLBUEFQAVAgAVABUQFQIAPBYkGQYZJgQGAAAAJgAcFQQZNQAGEBkYBVRvdGFsFQIWChbqARbmASaKBya2BhwYCA0CAAAAAAAAGAg1AQAAAAAAABYAKAgNAgAAAAAAABgINQEAAAAAAAAAGSwVBBUAFQIAFQAVEBUCADwpBhkmAAoAAAAmABwVBBk1AAYQGRgCSFAVAhYKFvwBFvABJvgIJpwIHBgIUAAAAAAAAAAYCCcAAAAAAAAAFgAoCFAAAAAAAAAAGAgnAAAAAAAAAAAZLBUEFQAVAgAVABUQFQIAPCkGGSYACgAAACYAHBUEGTUABhAZGAZBdHRhY2sVAhYKFvwBFvABJugKJowKHBgIUgAAAAAAAAAYCDEAAAAAAAAAFgAoCFIAAAAAAAAAGAgxAAAAAAAAAAAZLBUEFQAVAgAVABUQFQIAPCkGGSYACgAAACYAHBUEGTUABhAZGAdEZWZlbnNlFQIWChb8ARbwASbYDCb8CxwYCFMAAAAAAAAAGAgrAAAAAAAAABYAKAhTAAAAAAAAABgIKwAAAAAAAAAAGSwVBBUAFQIAFQAVEBUCADwpBhkmAAoAAAAmABwVBBk1AAYQGRgGU3BfQXRrFQIWChbqARbmASbADibsDRwYCGQAAAAAAAAAGAg8AAAAAAAAABYAKAhkAAAAAAAAABgIPAAAAAAAAAAAGSwVBBUAFQIAFQAVEBUCADwpBhkmAAoAAAAmABwVBBk1AAYQGRgGU3BfRGVmFQIWChbqARbmASamECbSDxwYCGQAAAAAAAAAGAgyAAAAAAAAABYAKAhkAAAAAAAAABgIMgAAAAAAAAAAGSwVBBUAFQIAFQAVEBUCADwpBhkmAAoAAAAmABwVBBk1AAYQGRgFU3BlZWQVAhYKFuoBFuYBJowSJrgRHBgIUAAAAAAAAAAYCC0AAAAAAAAAFgAoCFAAAAAAAAAAGAgtAAAAAAAAAAAZLBUEFQAVAgAVABUQFQIAPCkGGSYACgAAACYAHBUEGTUABhAZGApHZW5lcmF0aW9uFQIWCha4ARbAASbOEyaeExwYCAEAAAAAAAAAGAgBAAAAAAAAABYAKAgBAAAAAAAAABgIAQAAAAAAAAAAGSwVBBUAFQIAFQAVEBUCADwpBhkmAAoAAAAmABwVABklBgAZGAtpc0xlZ2VuZGFyeRUCFgoWUBZUJt4UPBgBABgBABYAKAEAGAEAABkcFQAVABUCADwpBhkmAAoAAAAmABwVDBk1AAYQGRgFQ29sb3IVAhYKFpABFpgBJvIVJrIVHDYAKANSZWQYBUdyZWVuABksFQQVABUCABUAFRAVAgA8FioZBhkmAAoAAAAmABwVABklBgAZGAloYXNHZW5kZXIVAhYKFlAWVCbKFjwYAQEYAQEWACgBARgBAQAZHBUAFQAVAgA8KQYZJgAKAAAAJgAcFQoZNQAGEBkYB1ByX01hbGUVAhYKFrgBFsABJs4XJp4XHBgIAAAAAAAA7D8YCAAAAAAAAOw/FgAoCAAAAAAAAOw/GAgAAAAAAADsPwAZLBUEFQAVAgAVABUQFQIAPCkGGSYACgAAACYAHBUMGTUABhAZGAtFZ2dfR3JvdXBfMRUCFgoWkgEWmgEmlBkm3hgcNgAoB01vbnN0ZXIYB01vbnN0ZXIAGSwVBBUAFQIAFQAVEBUCADwWRhkGGSYACgAAACYAHBUMGTUABhAZGAtFZ2dfR3JvdXBfMhUCFgoWnAEWpAEmvhom+BkcNgAoBUdyYXNzGAZEcmFnb24AGSwVBBUAFQIAFQAVEBUCADwWNhkGGSYACgAAACYAHBUAGSUGABkYEGhhc01lZ2FFdm9sdXRpb24VAhYKFlAWVCacGzwYAQEYAQAWACgBARgBAAAZHBUAFQAVAgA8KQYZJgAKAAAAJgAcFQoZNQAGEBkYCEhlaWdodF9tFQIWChb8ARb+ASbaHCbwGxwYCBSuR+F6FABAGAiF61G4HoXjPxYAKAgUrkfhehQAQBgIhetRuB6F4z8AGSwVBBUAFQIAFQAVEBUCADwpBhkmAAoAAAAmABwVChk1AAYQGRgJV2VpZ2h0X2tnFQIWChb8ARbuASbIHibuHRwYCAAAAAAAAFlAGAiamZmZmZkbQBYAKAgAAAAAAABZQBgImpmZmZmZG0AAGSwVBBUAFQIAFQAVEBUCADwpBhkmAAoAAAAmABwVBBk1AAYQGRgKQ2F0Y2hfUmF0ZRUCFgoWuAEWwAEmjCAm3B8cGAgtAAAAAAAAABgILQAAAAAAAAAWACgILQAAAAAAAAAYCC0AAAAAAAAAABksFQQVABUCABUAFRAVAgA8KQYZJgAKAAAAJgAcFQwZNQAGEBkYCkJvZHlfU3R5bGUVAhYKFswBFtQBJvohJpwhHDYAKAlxdWFkcnVwZWQYDmJpcGVkYWxfdGFpbGVkABksFQQVABUCABUAFRAVAgA8Fm4ZBhkmAAoAAAAW3CIWCiYIFugiABksGAZwYW5kYXMY9RZ7ImluZGV4X2NvbHVtbnMiOiBbeyJraW5kIjogInJhbmdlIiwgIm5hbWUiOiBudWxsLCAic3RhcnQiOiAwLCAic3RvcCI6IDUsICJzdGVwIjogMX1dLCAiY29sdW1uX2luZGV4ZXMiOiBbeyJuYW1lIjogbnVsbCwgImZpZWxkX25hbWUiOiBudWxsLCAicGFuZGFzX3R5cGUiOiAidW5pY29kZSIsICJudW1weV90eXBlIjogIm9iamVjdCIsICJtZXRhZGF0YSI6IHsiZW5jb2RpbmciOiAiVVRGLTgifX1dLCAiY29sdW1ucyI6IFt7Im5hbWUiOiAiTnVtYmVyIiwgImZpZWxkX25hbWUiOiAiTnVtYmVyIiwgInBhbmRhc190eXBlIjogImludDY0IiwgIm51bXB5X3R5cGUiOiAiaW50NjQiLCAibWV0YWRhdGEiOiBudWxsfSwgeyJuYW1lIjogIk5hbWUiLCAiZmllbGRfbmFtZSI6ICJOYW1lIiwgInBhbmRhc190eXBlIjogInVuaWNvZGUiLCAibnVtcHlfdHlwZSI6ICJvYmplY3QiLCAibWV0YWRhdGEiOiBudWxsfSwgeyJuYW1lIjogIlR5cGVfMSIsICJmaWVsZF9uYW1lIjogIlR5cGVfMSIsICJwYW5kYXNfdHlwZSI6ICJ1bmljb2RlIiwgIm51bXB5X3R5cGUiOiAib2JqZWN0IiwgIm1ldGFkYXRhIjogbnVsbH0sIHsibmFtZSI6ICJUeXBlXzIiLCAiZmllbGRfbmFtZSI6ICJUeXBlXzIiLCAicGFuZGFzX3R5cGUiOiAidW5pY29kZSIsICJudW1weV90eXBlIjogIm9iamVjdCIsICJtZXRhZGF0YSI6IG51bGx9LCB7Im5hbWUiOiAiVG90YWwiLCAiZmllbGRfbmFtZSI6ICJUb3RhbCIsICJwYW5kYXNfdHlwZSI6ICJpbnQ2NCIsICJudW1weV90eXBlIjogImludDY0IiwgIm1ldGFkYXRhIjogbnVsbH0sIHsibmFtZSI6ICJIUCIsICJmaWVsZF9uYW1lIjogIkhQIiwgInBhbmRhc190eXBlIjogImludDY0IiwgIm51bXB5X3R5cGUiOiAiaW50NjQiLCAibWV0YWRhdGEiOiBudWxsfSwgeyJuYW1lIjogIkF0dGFjayIsICJmaWVsZF9uYW1lIjogIkF0dGFjayIsICJwYW5kYXNfdHlwZSI6ICJpbnQ2NCIsICJudW1weV90eXBlIjogImludDY0IiwgIm1ldGFkYXRhIjogbnVsbH0sIHsibmFtZSI6ICJEZWZlbnNlIiwgImZpZWxkX25hbWUiOiAiRGVmZW5zZSIsICJwYW5kYXNfdHlwZSI6ICJpbnQ2NCIsICJudW1weV90eXBlIjogImludDY0IiwgIm1ldGFkYXRhIjogbnVsbH0sIHsibmFtZSI6ICJTcF9BdGsiLCAiZmllbGRfbmFtZSI6ICJTcF9BdGsiLCAicGFuZGFzX3R5cGUiOiAiaW50NjQiLCAibnVtcHlfdHlwZSI6ICJpbnQ2NCIsICJtZXRhZGF0YSI6IG51bGx9LCB7Im5hbWUiOiAiU3BfRGVmIiwgImZpZWxkX25hbWUiOiAiU3BfRGVmIiwgInBhbmRhc190eXBlIjogImludDY0IiwgIm51bXB5X3R5cGUiOiAiaW50NjQiLCAibWV0YWRhdGEiOiBudWxsfSwgeyJuYW1lIjogIlNwZWVkIiwgImZpZWxkX25hbWUiOiAiU3BlZWQiLCAicGFuZGFzX3R5cGUiOiAiaW50NjQiLCAibnVtcHlfdHlwZSI6ICJpbnQ2NCIsICJtZXRhZGF0YSI6IG51bGx9LCB7Im5hbWUiOiAiR2VuZXJhdGlvbiIsICJmaWVsZF9uYW1lIjogIkdlbmVyYXRpb24iLCAicGFuZGFzX3R5cGUiOiAiaW50NjQiLCAibnVtcHlfdHlwZSI6ICJpbnQ2NCIsICJtZXRhZGF0YSI6IG51bGx9LCB7Im5hbWUiOiAiaXNMZWdlbmRhcnkiLCAiZmllbGRfbmFtZSI6ICJpc0xlZ2VuZGFyeSIsICJwYW5kYXNfdHlwZSI6ICJib29sIiwgIm51bXB5X3R5cGUiOiAiYm9vbCIsICJtZXRhZGF0YSI6IG51bGx9LCB7Im5hbWUiOiAiQ29sb3IiLCAiZmllbGRfbmFtZSI6ICJDb2xvciIsICJwYW5kYXNfdHlwZSI6ICJ1bmljb2RlIiwgIm51bXB5X3R5cGUiOiAib2JqZWN0IiwgIm1ldGFkYXRhIjogbnVsbH0sIHsibmFtZSI6ICJoYXNHZW5kZXIiLCAiZmllbGRfbmFtZSI6ICJoYXNHZW5kZXIiLCAicGFuZGFzX3R5cGUiOiAiYm9vbCIsICJudW1weV90eXBlIjogImJvb2wiLCAibWV0YWRhdGEiOiBudWxsfSwgeyJuYW1lIjogIlByX01hbGUiLCAiZmllbGRfbmFtZSI6ICJQcl9NYWxlIiwgInBhbmRhc190eXBlIjogImZsb2F0NjQiLCAibnVtcHlfdHlwZSI6ICJmbG9hdDY0IiwgIm1ldGFkYXRhIjogbnVsbH0sIHsibmFtZSI6ICJFZ2dfR3JvdXBfMSIsICJmaWVsZF9uYW1lIjogIkVnZ19Hcm91cF8xIiwgInBhbmRhc190eXBlIjogInVuaWNvZGUiLCAibnVtcHlfdHlwZSI6ICJvYmplY3QiLCAibWV0YWRhdGEiOiBudWxsfSwgeyJuYW1lIjogIkVnZ19Hcm91cF8yIiwgImZpZWxkX25hbWUiOiAiRWdnX0dyb3VwXzIiLCAicGFuZGFzX3R5cGUiOiAidW5pY29kZSIsICJudW1weV90eXBlIjogIm9iamVjdCIsICJtZXRhZGF0YSI6IG51bGx9LCB7Im5hbWUiOiAiaGFzTWVnYUV2b2x1dGlvbiIsICJmaWVsZF9uYW1lIjogImhhc01lZ2FFdm9sdXRpb24iLCAicGFuZGFzX3R5cGUiOiAiYm9vbCIsICJudW1weV90eXBlIjogImJvb2wiLCAibWV0YWRhdGEiOiBudWxsfSwgeyJuYW1lIjogIkhlaWdodF9tIiwgImZpZWxkX25hbWUiOiAiSGVpZ2h0X20iLCAicGFuZGFzX3R5cGUiOiAiZmxvYXQ2NCIsICJudW1weV90eXBlIjogImZsb2F0NjQiLCAibWV0YWRhdGEiOiBudWxsfSwgeyJuYW1lIjogIldlaWdodF9rZyIsICJmaWVsZF9uYW1lIjogIldlaWdodF9rZyIsICJwYW5kYXNfdHlwZSI6ICJmbG9hdDY0IiwgIm51bXB5X3R5cGUiOiAiZmxvYXQ2NCIsICJtZXRhZGF0YSI6IG51bGx9LCB7Im5hbWUiOiAiQ2F0Y2hfUmF0ZSIsICJmaWVsZF9uYW1lIjogIkNhdGNoX1JhdGUiLCAicGFuZGFzX3R5cGUiOiAiaW50NjQiLCAibnVtcHlfdHlwZSI6ICJpbnQ2NCIsICJtZXRhZGF0YSI6IG51bGx9LCB7Im5hbWUiOiAiQm9keV9TdHlsZSIsICJmaWVsZF9uYW1lIjogIkJvZHlfU3R5bGUiLCAicGFuZGFzX3R5cGUiOiAidW5pY29kZSIsICJudW1weV90eXBlIjogIm9iamVjdCIsICJtZXRhZGF0YSI6IG51bGx9XSwgImNyZWF0b3IiOiB7ImxpYnJhcnkiOiAicHlhcnJvdyIsICJ2ZXJzaW9uIjogIjIxLjAuMCJ9LCAicGFuZGFzX3ZlcnNpb24iOiAiMi4zLjMifQAYDEFSUk9XOnNjaGVtYRiMLC8vLy8vNEFRQUFBUUFBQUFBQUFLQUE0QUJnQUZBQWdBQ2dBQUFBQUJCQUFRQUFBQUFBQUtBQXdBQUFBRUFBZ0FDZ0FBQUt3TEFBQUVBQUFBQVFBQUFBd0FBQUFJQUF3QUJBQUlBQWdBQUFDRUN3QUFCQUFBQUhVTEFBQjdJbWx1WkdWNFgyTnZiSFZ0Ym5NaU9pQmJleUpyYVc1a0lqb2dJbkpoYm1kbElpd2dJbTVoYldVaU9pQnVkV3hzTENBaWMzUmhjblFpT2lBd0xDQWljM1J2Y0NJNklEVXNJQ0p6ZEdWd0lqb2dNWDFkTENBaVkyOXNkVzF1WDJsdVpHVjRaWE1pT2lCYmV5SnVZVzFsSWpvZ2JuVnNiQ3dnSW1acFpXeGtYMjVoYldVaU9pQnVkV3hzTENBaWNHRnVaR0Z6WDNSNWNHVWlPaUFpZFc1cFkyOWtaU0lzSUNKdWRXMXdlVjkwZVhCbElqb2dJbTlpYW1WamRDSXNJQ0p0WlhSaFpHRjBZU0k2SUhzaVpXNWpiMlJwYm1jaU9pQWlWVlJHTFRnaWZYMWRMQ0FpWTI5c2RXMXVjeUk2SUZ0N0ltNWhiV1VpT2lBaVRuVnRZbVZ5SWl3Z0ltWnBaV3hrWDI1aGJXVWlPaUFpVG5WdFltVnlJaXdnSW5CaGJtUmhjMTkwZVhCbElqb2dJbWx1ZERZMElpd2dJbTUxYlhCNVgzUjVjR1VpT2lBaWFXNTBOalFpTENBaWJXVjBZV1JoZEdFaU9pQnVkV3hzZlN3Z2V5SnVZVzFsSWpvZ0lrNWhiV1VpTENBaVptbGxiR1JmYm1GdFpTSTZJQ0pPWVcxbElpd2dJbkJoYm1SaGMxOTBlWEJsSWpvZ0luVnVhV052WkdVaUxDQWliblZ0Y0hsZmRIbHdaU0k2SUNKdlltcGxZM1FpTENBaWJXVjBZV1JoZEdFaU9pQnVkV3hzZlN3Z2V5SnVZVzFsSWpvZ0lsUjVjR1ZmTVNJc0lDSm1hV1ZzWkY5dVlXMWxJam9nSWxSNWNHVmZNU0lzSUNKd1lXNWtZWE5mZEhsd1pTSTZJQ0oxYm1samIyUmxJaXdnSW01MWJYQjVYM1I1Y0dVaU9pQWliMkpxWldOMElpd2dJbTFsZEdGa1lYUmhJam9nYm5Wc2JIMHNJSHNpYm1GdFpTSTZJQ0pVZVhCbFh6SWlMQ0FpWm1sbGJHUmZibUZ0WlNJNklDSlVlWEJsWHpJaUxDQWljR0Z1WkdGelgzUjVjR1VpT2lBaWRXNXBZMjlrWlNJc0lDSnVkVzF3ZVY5MGVYQmxJam9nSW05aWFtVmpkQ0lzSUNKdFpYUmhaR0YwWVNJNklHNTFiR3g5TENCN0ltNWhiV1VpT2lBaVZHOTBZV3dpTENBaVptbGxiR1JmYm1GdFpTSTZJQ0pVYjNSaGJDSXNJQ0p3WVc1a1lYTmZkSGx3WlNJNklDSnBiblEyTkNJc0lDSnVkVzF3ZVY5MGVYQmxJam9nSW1sdWREWTBJaXdnSW0xbGRHRmtZWFJoSWpvZ2JuVnNiSDBzSUhzaWJtRnRaU0k2SUNKSVVDSXNJQ0ptYVdWc1pGOXVZVzFsSWpvZ0lraFFJaXdnSW5CaGJtUmhjMTkwZVhCbElqb2dJbWx1ZERZMElpd2dJbTUxYlhCNVgzUjVjR1VpT2lBaWFXNTBOalFpTENBaWJXVjBZV1JoZEdFaU9pQnVkV3hzZlN3Z2V5SnVZVzFsSWpvZ0lrRjBkR0ZqYXlJc0lDSm1hV1ZzWkY5dVlXMWxJam9nSWtGMGRHRmpheUlzSUNKd1lXNWtZWE5mZEhsd1pTSTZJQ0pwYm5RMk5DSXNJQ0p1ZFcxd2VWOTBlWEJsSWpvZ0ltbHVkRFkwSWl3Z0ltMWxkR0ZrWVhSaElqb2diblZzYkgwc0lIc2libUZ0WlNJNklDSkVaV1psYm5ObElpd2dJbVpwWld4a1gyNWhiV1VpT2lBaVJHVm1aVzV6WlNJc0lDSndZVzVrWVhOZmRIbHdaU0k2SUNKcGJuUTJOQ0lzSUNKdWRXMXdlVjkwZVhCbElqb2dJbWx1ZERZMElpd2dJbTFsZEdGa1lYUmhJam9nYm5Wc2JIMHNJSHNpYm1GdFpTSTZJQ0pUY0Y5QmRHc2lMQ0FpWm1sbGJHUmZibUZ0WlNJNklDSlRjRjlCZEdzaUxDQWljR0Z1WkdGelgzUjVjR1VpT2lBaWFXNTBOalFpTENBaWJuVnRjSGxmZEhsd1pTSTZJQ0pwYm5RMk5DSXNJQ0p0WlhSaFpHRjBZU0k2SUc1MWJHeDlMQ0I3SW01aGJXVWlPaUFpVTNCZlJHVm1JaXdnSW1acFpXeGtYMjVoYldVaU9pQWlVM0JmUkdWbUlpd2dJbkJoYm1SaGMxOTBlWEJsSWpvZ0ltbHVkRFkwSWl3Z0ltNTFiWEI1WDNSNWNHVWlPaUFpYVc1ME5qUWlMQ0FpYldWMFlXUmhkR0VpT2lCdWRXeHNmU3dnZXlKdVlXMWxJam9nSWxOd1pXVmtJaXdnSW1acFpXeGtYMjVoYldVaU9pQWlVM0JsWldRaUxDQWljR0Z1WkdGelgzUjVjR1VpT2lBaWFXNTBOalFpTENBaWJuVnRjSGxmZEhsd1pTSTZJQ0pwYm5RMk5DSXNJQ0p0WlhSaFpHRjBZU0k2SUc1MWJHeDlMQ0I3SW01aGJXVWlPaUFpUjJWdVpYSmhkR2x2YmlJc0lDSm1hV1ZzWkY5dVlXMWxJam9nSWtkbGJtVnlZWFJwYjI0aUxDQWljR0Z1WkdGelgzUjVjR1VpT2lBaWFXNTBOalFpTENBaWJuVnRjSGxmZEhsd1pTSTZJQ0pwYm5RMk5DSXNJQ0p0WlhSaFpHRjBZU0k2SUc1MWJHeDlMQ0I3SW01aGJXVWlPaUFpYVhOTVpXZGxibVJoY25raUxDQWlabWxsYkdSZmJtRnRaU0k2SUNKcGMweGxaMlZ1WkdGeWVTSXNJQ0p3WVc1a1lYTmZkSGx3WlNJNklDSmliMjlzSWl3Z0ltNTFiWEI1WDNSNWNHVWlPaUFpWW05dmJDSXNJQ0p0WlhSaFpHRjBZU0k2SUc1MWJHeDlMQ0I3SW01aGJXVWlPaUFpUTI5c2IzSWlMQ0FpWm1sbGJHUmZibUZ0WlNJNklDSkRiMnh2Y2lJc0lDSndZVzVrWVhOZmRIbHdaU0k2SUNKMWJtbGpiMlJsSWl3Z0ltNTFiWEI1WDNSNWNHVWlPaUFpYjJKcVpXTjBJaXdnSW0xbGRHRmtZWFJoSWpvZ2JuVnNiSDBzSUhzaWJtRnRaU0k2SUNKb1lYTkhaVzVrWlhJaUxDQWlabWxsYkdSZmJtRnRaU0k2SUNKb1lYTkhaVzVrWlhJaUxDQWljR0Z1WkdGelgzUjVjR1VpT2lBaVltOXZiQ0lzSUNKdWRXMXdlVjkwZVhCbElqb2dJbUp2YjJ3aUxDQWliV1YwWVdSaGRHRWlPaUJ1ZFd4c2ZTd2dleUp1WVcxbElqb2dJbEJ5WDAxaGJHVWlMQ0FpWm1sbGJHUmZibUZ0WlNJNklDSlFjbDlOWVd4bElpd2dJbkJoYm1SaGMxOTBlWEJsSWpvZ0ltWnNiMkYwTmpRaUxDQWliblZ0Y0hsZmRIbHdaU0k2SUNKbWJHOWhkRFkwSWl3Z0ltMWxkR0ZrWVhSaElqb2diblZzYkgwc0lIc2libUZ0WlNJNklDSkZaMmRmUjNKdmRYQmZNU0lzSUNKbWFXVnNaRjl1WVcxbElqb2dJa1ZuWjE5SGNtOTFjRjh4SWl3Z0luQmhibVJoYzE5MGVYQmxJam9nSW5WdWFXTnZaR1VpTENBaWJuVnRjSGxmZEhsd1pTSTZJQ0p2WW1wbFkzUWlMQ0FpYldWMFlXUmhkR0VpT2lCdWRXeHNmU3dnZXlKdVlXMWxJam9nSWtWbloxOUhjbTkxY0Y4eUlpd2dJbVpwWld4a1gyNWhiV1VpT2lBaVJXZG5YMGR5YjNWd1h6SWlMQ0FpY0dGdVpHRnpYM1I1Y0dVaU9pQWlkVzVwWTI5a1pTSXNJQ0p1ZFcxd2VWOTBlWEJsSWpvZ0ltOWlhbVZqZENJc0lDSnRaWFJoWkdGMFlTSTZJRzUxYkd4OUxDQjdJbTVoYldVaU9pQWlhR0Z6VFdWbllVVjJiMngxZEdsdmJpSXNJQ0ptYVdWc1pGOXVZVzFsSWpvZ0ltaGhjMDFsWjJGRmRtOXNkWFJwYjI0aUxDQWljR0Z1WkdGelgzUjVjR1VpT2lBaVltOXZiQ0lzSUNKdWRXMXdlVjkwZVhCbElqb2dJbUp2YjJ3aUxDQWliV1YwWVdSaGRHRWlPaUJ1ZFd4c2ZTd2dleUp1WVcxbElqb2dJa2hsYVdkb2RGOXRJaXdnSW1acFpXeGtYMjVoYldVaU9pQWlTR1ZwWjJoMFgyMGlMQ0FpY0dGdVpHRnpYM1I1Y0dVaU9pQWlabXh2WVhRMk5DSXNJQ0p1ZFcxd2VWOTBlWEJsSWpvZ0ltWnNiMkYwTmpRaUxDQWliV1YwWVdSaGRHRWlPaUJ1ZFd4c2ZTd2dleUp1WVcxbElqb2dJbGRsYVdkb2RGOXJaeUlzSUNKbWFXVnNaRjl1WVcxbElqb2dJbGRsYVdkb2RGOXJaeUlzSUNKd1lXNWtZWE5mZEhsd1pTSTZJQ0ptYkc5aGREWTBJaXdnSW01MWJYQjVYM1I1Y0dVaU9pQWlabXh2WVhRMk5DSXNJQ0p0WlhSaFpHRjBZU0k2SUc1MWJHeDlMQ0I3SW01aGJXVWlPaUFpUTJGMFkyaGZVbUYwWlNJc0lDSm1hV1ZzWkY5dVlXMWxJam9nSWtOaGRHTm9YMUpoZEdVaUxDQWljR0Z1WkdGelgzUjVjR1VpT2lBaWFXNTBOalFpTENBaWJuVnRjSGxmZEhsd1pTSTZJQ0pwYm5RMk5DSXNJQ0p0WlhSaFpHRjBZU0k2SUc1MWJHeDlMQ0I3SW01aGJXVWlPaUFpUW05a2VWOVRkSGxzWlNJc0lDSm1hV1ZzWkY5dVlXMWxJam9nSWtKdlpIbGZVM1I1YkdVaUxDQWljR0Z1WkdGelgzUjVjR1VpT2lBaWRXNXBZMjlrWlNJc0lDSnVkVzF3ZVY5MGVYQmxJam9nSW05aWFtVmpkQ0lzSUNKdFpYUmhaR0YwWVNJNklHNTFiR3g5WFN3Z0ltTnlaV0YwYjNJaU9pQjdJbXhwWW5KaGNua2lPaUFpY0hsaGNuSnZkeUlzSUNKMlpYSnphVzl1SWpvZ0lqSXhMakF1TUNKOUxDQWljR0Z1WkdGelgzWmxjbk5wYjI0aU9pQWlNaTR6TGpNaWZRQUFBQVlBQUFCd1lXNWtZWE1BQUJjQUFBQm9CQUFBS0FRQUFQd0RBQURRQXdBQW5BTUFBR3dEQUFBNEF3QUFCQU1BQU5BQ0FBQ2NBZ0FBYUFJQUFEQUNBQUFBQWdBQTFBRUFBS1FCQUFCc0FRQUFQQUVBQUF3QkFBRFVBQUFBb0FBQUFHd0FBQUEwQUFBQUJBQUFBQVQ4Ly84QUFBRUZFQUFBQUJ3QUFBQUVBQUFBQUFBQUFBb0FBQUJDYjJSNVgxTjBlV3hsQUFBMC9QLy9NUHovL3dBQUFRSVFBQUFBSEFBQUFBUUFBQUFBQUFBQUNnQUFBRU5oZEdOb1gxSmhkR1VBQUNUOC8vOEFBQUFCUUFBQUFHVDgvLzhBQUFFREVBQUFBQndBQUFBRUFBQUFBQUFBQUFrQUFBQlhaV2xuYUhSZmEyY0FBQUFXLy8vL0FBQUNBSlQ4Ly84QUFBRURFQUFBQUJ3QUFBQUVBQUFBQUFBQUFBZ0FBQUJJWldsbmFIUmZiUUFBQUFCRy8vLy9BQUFDQU1UOC8vOEFBQUVHRUFBQUFDUUFBQUFFQUFBQUFBQUFBQkFBQUFCb1lYTk5aV2RoUlhadmJIVjBhVzl1QUFBQUFQejgvLy80L1AvL0FBQUJCUkFBQUFBY0FBQUFCQUFBQUFBQUFBQUxBQUFBUldkblgwZHliM1Z3WHpJQUtQMy8veVQ5Ly84QUFBRUZFQUFBQUJ3QUFBQUVBQUFBQUFBQUFBc0FBQUJGWjJkZlIzSnZkWEJmTVFCVS9mLy9VUDMvL3dBQUFRTVFBQUFBSUFBQUFBUUFBQUFBQUFBQUJ3QUFBRkJ5WDAxaGJHVUFBQUFHQUFnQUJnQUdBQUFBQUFBQ0FJVDkvLzhBQUFFR0VBQUFBQndBQUFBRUFBQUFBQUFBQUFrQUFBQm9ZWE5IWlc1a1pYSUFBQUMwL2YvL3NQMy8vd0FBQVFVUUFBQUFHQUFBQUFRQUFBQUFBQUFBQlFBQUFFTnZiRzl5QUFBQTNQMy8vOWo5Ly84QUFBRUdFQUFBQUJ3QUFBQUVBQUFBQUFBQUFBc0FBQUJwYzB4bFoyVnVaR0Z5ZVFBSS92Ly9CUDcvL3dBQUFRSVFBQUFBSEFBQUFBUUFBQUFBQUFBQUNnQUFBRWRsYm1WeVlYUnBiMjRBQVBqOS8vOEFBQUFCUUFBQUFEaisvLzhBQUFFQ0VBQUFBQmdBQUFBRUFBQUFBQUFBQUFVQUFBQlRjR1ZsWkFBQUFDaisvLzhBQUFBQlFBQUFBR2orLy84QUFBRUNFQUFBQUJnQUFBQUVBQUFBQUFBQUFBWUFBQUJUY0Y5RVpXWUFBRmorLy84QUFBQUJRQUFBQUpqKy8vOEFBQUVDRUFBQUFCZ0FBQUFFQUFBQUFBQUFBQVlBQUFCVGNGOUJkR3NBQUlqKy8vOEFBQUFCUUFBQUFNaisvLzhBQUFFQ0VBQUFBQmdBQUFBRUFBQUFBQUFBQUFjQUFBQkVaV1psYm5ObEFMaisvLzhBQUFBQlFBQUFBUGorLy84QUFBRUNFQUFBQUJnQUFBQUVBQUFBQUFBQUFBWUFBQUJCZEhSaFkyc0FBT2orLy84QUFBQUJRQUFBQUNqLy8vOEFBQUVDRUFBQUFCUUFBQUFFQUFBQUFBQUFBQUlBQUFCSVVBQUFGUC8vL3dBQUFBRkFBQUFBVlAvLy93QUFBUUlRQUFBQUdBQUFBQVFBQUFBQUFBQUFCUUFBQUZSdmRHRnNBQUFBUlAvLy93QUFBQUZBQUFBQWhQLy8vd0FBQVFVUUFBQUFHQUFBQUFRQUFBQUFBQUFBQmdBQUFGUjVjR1ZmTWdBQXNQLy8vNnovLy84QUFBRUZFQUFBQUJnQUFBQUVBQUFBQUFBQUFBWUFBQUJVZVhCbFh6RUFBTmovLy8vVS8vLy9BQUFCQlJBQUFBQWNBQUFBQkFBQUFBQUFBQUFFQUFBQVRtRnRaUUFBQUFBRUFBUUFCQUFBQUJBQUZBQUlBQVlBQndBTUFBQUFFQUFRQUFBQUFBQUJBaEFBQUFBZ0FBQUFCQUFBQUFBQUFBQUdBQUFBVG5WdFltVnlBQUFJQUF3QUNBQUhBQWdBQUFBQUFBQUJRQUFBQUFBQUFBQT0AGCBwYXJxdWV0LWNwcC1hcnJvdyB2ZXJzaW9uIDIxLjAuMBn8FxwAABwAABwAABwAABwAABwAABwAABwAABwAABwAABwAABwAABwAABwAABwAABwAABwAABwAABwAABwAABwAABwAABwAAAAzLAAAUEFSMQ=="
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# **2. Split that into train and test**"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "X_train, X_test, y_train, y_test, X_train_raw, y_train_raw = prepare_data(df)\n\nprint(f\"Number of Features: {len(X_train.columns)}\")\nprint(\"X_train shape:\", X_train.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"y_test shape:\", y_test.shape)",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of Features: 20\nX_train shape: (1078, 20)\nX_test shape: (145, 20)\ny_train shape: (1078,)\ny_test shape: (145,)\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **3. Define a metric to evaluate a machine learning model**\nSince our model will be a binary classifier, we will use `accuracy` as the primary metric to evaluate our model. However, in MLflow, we will log both `accuracy` and `F1-score` in the `log_model_metrics()` function."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **4. Build a pipeline using Airflow or MLflow or your platform pipeline to train a machine learning model using the train dataset (use AutoML to refine the category of algorithms).**\nFor our workflow, we will first use AWS AutoML to determine the optimal algorithm category, and then MLflow as the pipeline for training our machine learning model."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 4a. Use AWS AutoML to determine the optimal algorithm category\nIn order to use AWS AutoML, we will first upload our training data to S3, and then use it to with the AutoML model."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Combine the training data\ntrain_df = pd.concat([\n    pd.DataFrame(X_train, columns= X_train.columns if hasattr(X_train, 'columns') else None),\n    pd.Series(y_train, name= 'hasMegaEvolution')\n], axis= 1)\n\n# Save it locally and then upload it to S3\ntrain_df.to_csv('pokemon_train.csv', index= False)\n\nS3_CLIENT.upload_file('pokemon_train.csv', BUCKET_NAME, 'automl/input/pokemon_train.csv')\n\nprint(\"Data uploaded to S3\")\nprint(f\"- s3://{BUCKET_NAME}/automl/input/pokemon_train.csv\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data uploaded to S3\n- s3://ml-ops-fp/automl/input/pokemon_train.csv\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "With AWS AutoML, we will try seven candidate algorithms, allotting only 3 minutes (180 seconds) for each candidate or 21 total minutes (1,260 seconds) for cost minimization. However, these should still provide enough signal to determine the best algorithm category."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Set the training data location\nTRAIN_S3_PATH = f's3://{BUCKET_NAME}/automl/input/pokemon_train.csv'\nOUTPUT_S3_PATH = f's3://{BUCKET_NAME}/automl/output'\n\n# Create an AWS AutoML job\ntimestamp = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\nautoml = AutoML(\n    role= ROLE_ARN,\n    target_attribute_name= 'hasMegaEvolution',\n    output_path= OUTPUT_S3_PATH,\n    base_job_name= 'pokemon-automl',\n    sagemaker_session= SESSION,\n    problem_type= 'BinaryClassification',\n    max_candidates= 7,\n    max_runtime_per_training_job_in_seconds= 180,\n    total_job_runtime_in_seconds= 1260,\n    job_objective= {'MetricName': 'Accuracy'},\n    mode= 'HYPERPARAMETER_TUNING'\n)\n\n# Start the AutoML job\nprint(\"Starting AutoML job...\")\nautoml.fit(\n    inputs= TRAIN_S3_PATH,\n    wait= False,\n    logs= False\n)\n\njob_name = automl.current_job_name\nprint(f\"AutoML job started: {job_name}\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Starting AutoML job...\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "AutoML job started: pokemon--2025-12-08-19-02-49-681\n"
        },
        {
          "output_type": "display_data",
          "data": {},
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Check AutoML status\nstatus = automl.describe_auto_ml_job()\n\nprint(f\"Job Name: {status['AutoMLJobName']}\")\nprint(f\"Status: {status['AutoMLJobStatus']}\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {},
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Job Name: pokemon--2025-12-08-19-02-49-681\nStatus: Completed\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Get best candidate only\nbest = automl.best_candidate()\n\nprint(\"=\"*70)\nprint(\"BEST MODEL HYPERPARAMETERS\")\nprint(\"=\"*70)\n\nname = best['CandidateName']\nmetric = best['FinalAutoMLJobObjectiveMetric']['Value']\n\nprint(f\"\\nModel: {name}\")\nprint(f\"Accuracy: {metric:.4f} ({metric*100:.2f}%)\")\nprint(f\"\\n{'='*70}\")\n\n# Get training job details\nfor step in best.get('CandidateSteps', []):\n    if step['CandidateStepType'] == 'AWS::SageMaker::TrainingJob':\n        training_job_name = step['CandidateStepArn'].split('/')[-1]\n        \n        try:\n            training_job = SM_CLIENT.describe_training_job(\n                TrainingJobName= training_job_name\n            )\n            \n            hyperparams = training_job.get('HyperParameters', {})\n            \n            # Extract algorithm details\n            print(f\"\\nHyperparameters:\")\n            \n            # Look for key parameters that indicate the algorithm\n            key_params = [\n                'predictor_type', 'algorithm', 'estimator', \n                'max_depth', 'n_estimators', 'learning_rate',\n                'booster', 'tree_method', 'model_type', 'eta', 'num_round'\n            ]\n            \n            algorithm_found = False\n            for param in key_params:\n                if param in hyperparams:\n                    print(f\"  {param}: {hyperparams[param]}\")\n                    algorithm_found = True\n            \n            # If specific params found, print all\n            if algorithm_found:\n                print(f\"\\n  All Hyperparameters:\")\n                for key, value in sorted(hyperparams.items()):\n                    if key not in key_params:\n                        print(f\"    {key}: {value}\")\n            else:\n                # Print everything if we didn't find specific indicators\n                for key, value in sorted(hyperparams.items()):\n                    print(f\"  {key}: {value}\")\n                    \n        except Exception as e:\n            print(f\"  Error getting training job: {e}\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {},
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "======================================================================\nBEST MODEL HYPERPARAMETERS\n======================================================================\n\nModel: pokemon--2025-12-08-19-02-49-62u-003-c9d165ab\nAccuracy: 0.9731 (97.31%)\n\n======================================================================\n\nHyperparameters:\n  processor_module: candidate_data_processors.dpp4\n  sagemaker_program: candidate_data_processors.trainer\n  sagemaker_submit_directory: /opt/ml/input/data/code\n\nHyperparameters:\n  max_depth: 4\n  eta: 0.6641367908850111\n  num_round: 364\n\n  All Hyperparameters:\n    _kfold: 5\n    _tuning_objective_metric: validation:accuracy\n    alpha: 1.5323566593501716e-06\n    colsample_bytree: 0.9597047988623544\n    eval_metric: accuracy,f1_binary,auc,balanced_accuracy,precision,recall,logloss\n    gamma: 0.00035887647058464487\n    lambda: 0.9645996772792648\n    min_child_weight: 0.002811123203178802\n    objective: binary:logistic\n    subsample: 0.7488351445742566\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Since these are gradient boosting parameters, we know that the best model must be an gradient boosting algorithm."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 4b. Use MLflow to create a pipeline for training a machine learning model\nSince we know from AWS AutoML that the best algorithm is Gradient Boosting, we will run expriments via a MLflow pipeline to determine the optimal set of hyperparameters. Note: since this notebook was created in Sagemaker for AWS AutoML use, MLflow must be used locally since Sagemaker does not support server MLflow usage"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "PARAM_DIST = {\n    'n_estimators': [2, 3, 5, 7],\n    'learning_rate': uniform(0.01, 0.1),\n    'max_depth': randint(2, 4),\n    'min_samples_split': randint(5, 20)\n}\nrandom_grid = sample_params(\n    PARAM_DIST, \n    n_samples= 10, \n    random_state= RANDOM_SEED\n)",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Set up MLflow\nmlflow.set_tracking_uri(\"file:./mlruns\")\nmlflow.set_experiment('Pokemon')\n\n# Verify MLflow tracking\nprint(f\"Tracking URI: {mlflow.get_tracking_uri()}\")\nprint(f\"Experiment: {mlflow.get_experiment_by_name('Pokemon')}\\n\")\n\n# Run the expriments to find the best model\nEXPERIMENT_NAME = 'Pokemon'\nfor i, params in enumerate(random_grid):\n    print(f\"[{i+1}/{len(random_grid)}] Training model with params: {params}\")\n    mlflow_pipeline(\n        features= X_train,\n        target= y_train,\n        random_seed= RANDOM_SEED,\n        run_name= f'run_{i + 1}',\n        experiment_name= EXPERIMENT_NAME,\n        **params\n    )\n\nprint(\"\\nAll experiments logged to ./mlruns/\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tracking URI: file:./mlruns\nExperiment: <Experiment: artifact_location='file:///home/sagemaker-user/mlruns/504153010705164362', creation_time=1765139956628, experiment_id='504153010705164362', last_update_time=1765139956628, lifecycle_stage='active', name='Pokemon', tags={}>\n\n[1/10] Training model with params: {'n_estimators': 2, 'learning_rate': 0.053887843975205234, 'max_depth': 3, 'min_samples_split': 11}\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[2/10] Training model with params: {'n_estimators': 7, 'learning_rate': 0.07973680290593639, 'max_depth': 2, 'min_samples_split': 6}\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[3/10] Training model with params: {'n_estimators': 5, 'learning_rate': 0.0861139701990353, 'max_depth': 3, 'min_samples_split': 15}\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[4/10] Training model with params: {'n_estimators': 7, 'learning_rate': 0.02281136326755459, 'max_depth': 3, 'min_samples_split': 11}\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[5/10] Training model with params: {'n_estimators': 5, 'learning_rate': 0.10267649888486018, 'max_depth': 2, 'min_samples_split': 16}\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[6/10] Training model with params: {'n_estimators': 5, 'learning_rate': 0.092276161327083, 'max_depth': 3, 'min_samples_split': 11}\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[7/10] Training model with params: {'n_estimators': 3, 'learning_rate': 0.06545847870158349, 'max_depth': 2, 'min_samples_split': 18}\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[8/10] Training model with params: {'n_estimators': 2, 'learning_rate': 0.09276311719925821, 'max_depth': 2, 'min_samples_split': 14}\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[9/10] Training model with params: {'n_estimators': 2, 'learning_rate': 0.04545259681298684, 'max_depth': 3, 'min_samples_split': 6}\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[10/10] Training model with params: {'n_estimators': 7, 'learning_rate': 0.09931211213221977, 'max_depth': 3, 'min_samples_split': 16}\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nAll experiments logged to ./mlruns/\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Get all runs from the MLflow experiments\nexperiment = mlflow.get_experiment_by_name('Pokemon')\nruns = mlflow.search_runs(experiment_ids= [experiment.experiment_id])\n\n\n# Sort and print the restults\nprint(\"Experiment Results:\")\nprint(runs[[\n    'metrics.accuracy', \n    'params.n_estimators',\n    'params.learning_rate',\n    'params.max_depth',\n    'params.min_samples_split',\n]].head(10).to_string())\n\n# Show best run hyperparameters\nbest_run = runs.sort_values('metrics.accuracy', ascending= False).iloc[0]\nprint(\"\\nBest Model Parameters:\")\nprint(best_run)",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Experiment Results:\n   metrics.accuracy params.n_estimators  params.learning_rate params.max_depth params.min_samples_split\n0          0.933210                   7   0.09931211213221977                3                       16\n1          0.912801                   2   0.04545259681298684                3                        6\n2          0.846939                   2   0.09276311719925821                2                       14\n3          0.857143                   3   0.06545847870158349                2                       18\n4          0.916512                   5     0.092276161327083                3                       11\n5          0.880334                   5   0.10267649888486018                2                       16\n6          0.895176                   7   0.02281136326755459                3                       11\n7          0.916512                   5    0.0861139701990353                3                       15\n8          0.879406                   7   0.07973680290593639                2                        6\n9          0.912801                   2  0.053887843975205234                3                       11\n\nBest Model Parameters:\nrun_id                                       7e5090756e9e43078c50c4d4732e4989\nexperiment_id                                              504153010705164362\nstatus                                                               FINISHED\nartifact_uri                file:///home/sagemaker-user/mlruns/50415301070...\nstart_time                                   2025-12-09 17:15:11.396000+00:00\nend_time                                     2025-12-09 17:15:15.023000+00:00\nmetrics.recall                                                        0.96475\nmetrics.f1                                                           0.935252\nmetrics.accuracy                                                      0.93321\nmetrics.precision                                                    0.907504\nparams.n_estimators                                                         7\nparams.max_depth                                                            3\nparams.learning_rate                                      0.09931211213221977\nparams.min_samples_split                                                   16\ntags.mlflow.source.type                                                 LOCAL\ntags.mlflow.source.name     /smus_kernel_server/.venv/lib/python3.11/site-...\ntags.mlflow.user                                               sagemaker-user\ntags.mlflow.runName                                                    run_10\nName: 0, dtype: object\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "As seen above, the best model is a gradient boosting model with 7 estimators, a max depth of 3, and a minimum of 16 samples to split. "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **5. Deploy the model for inference**\nWe will deploy our model to AWS."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 5a. Convert the best MLflow model to a native XG-Boost model\nTo deploy via AWS, the model must be a native XG-Boost model Thus, we will use the exact hyperparameters from the best MLflow model to create a native XG-Boost model via the `XGBoost` library."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "best_run = runs.sort_values('metrics.accuracy', ascending= False).iloc[0]\n\n# Extract hyperparameters\nbest_params = {\n    'n_estimators': int(best_run['params.n_estimators']),\n    'learning_rate': float(best_run['params.learning_rate']),\n    'max_depth': int(best_run['params.max_depth']),\n    'min_samples_split': int(best_run['params.min_samples_split'])\n}\n\n# Map sklearn params to XGBoost params\nxgb_params = {\n    'n_estimators': best_params['n_estimators'],\n    'learning_rate': best_params['learning_rate'],\n    'max_depth': best_params['max_depth'],\n    'min_child_weight': best_params['min_samples_split'],\n    'objective': 'binary:logistic',\n    'eval_metric': 'logloss',\n    'use_label_encoder': False,\n    'random_state': RANDOM_SEED\n}\n\nprint(\"Training XG-Boost model with the optimal hyperparameters...\")\n\n# Train XGBoost model\nxgb_model = xgb.XGBClassifier(**xgb_params)\nxgb_model.fit(X_train, y_train)\n\n# Evaluate\ny_pred = xgb_model.predict(X_test)\nxgb_accuracy = accuracy_score(y_test, y_pred)\nxgb_f1 = f1_score(y_test, y_pred)\n\nprint(f\"\\nXG-Boost model trained\")\nprint(f\"- Accuracy: {xgb_accuracy:.4f}\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training XG-Boost model with the optimal hyperparameters...\n\nXG-Boost model trained\n- Accuracy: 0.8828\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 5b. Deploy the native XG-Boost model to AWS for inference"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Set S3 configurations for model saving\nMODEL_KEY = 'model/model.tar.gz'\nMODEL_S3_PATH = f's3://{BUCKET_NAME}/{MODEL_KEY}'\nENDPOINT_NAME = 'pokemon-model'\n\n# Save the model\nxgb_model.save_model('xgboost-model')\n\n# Convert to tar.gz format (SageMaker requirement)\nwith tarfile.open('model.tar.gz', 'w:gz') as tar:\n    tar.add('xgboost-model')\nprint(\"Model packaged as model.tar.gz\")\n\n# Upload to S3\nS3_CLIENT.upload_file(\n    Filename='model.tar.gz',\n    Bucket=BUCKET_NAME,\n    Key= MODEL_KEY\n)\nprint(f\"Model uploaded to: {S3_PATH}\")\n\nxgb_model_sm = XGBoostModel(\n    model_data= MODEL_S3_PATH,\n    role= ROLE_ARN,\n    framework_version= '1.7-1',\n    sagemaker_session= SESSION\n)\n\nprint(\"\\nDeploying model to SageMaker endpoint...\")\n\n# Deploy to endpoint\ntry:\n    predictor = xgb_model_sm.deploy(\n        initial_instance_count= 1,\n        instance_type= 'ml.m5.large',\n        endpoint_name= ENDPOINT_NAME\n    )\n    print(\"\\nModel successfully deployed\")\n    print(f\"- Endpoint name: {ENDPOINT_NAME}\")\n    print(f\"- Model location: {MODEL_S3_PATH}\")\n    print(f\"- Instance type: ml.m5.large\")\n    \nexcept Exception as e:\n    if 'Cannot create already existing endpoint' in str(e) or 'already exists' in str(e):\n        print(f\"\\nModel already deployed\")\n        print(f\"- Endpoint name: {ENDPOINT_NAME}\")\n        print(f\"- Model location: {MODEL_S3_PATH}\")\n        print(f\"- Instance type: ml.m5.large\")\n    else:\n        raise",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model packaged as model.tar.gz\nModel uploaded to: s3://ml-ops-fp/pokemon-data/pokemon.csv\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nDeploying model to SageMaker endpoint...\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nModel already deployed\n- Endpoint name: pokemon-model\n- Model location: s3://ml-ops-fp/model/model.tar.gz\n- Instance type: ml.m5.large\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **6. Set up model monitoring (if there is a monitoring dashboard show that)**\nIn order to establish a baseline, we will use the training data (`X_train`) for data input drift detection."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Prepare baseline data for drift comparison\nbaseline_data = X_train_raw.copy()\n\nprint(f\"Baseline data prepared:\")\nprint(f\"  - Shape: {baseline_data.shape}\")\nprint(f\"  - Features: {baseline_data.shape[1]}\")\nprint(f\"  - Samples: {baseline_data.shape[0]}\")\n\nprint(\"\\nMonitoring configuration complete\")\nprint(\"  - Monitoring tool: Evidently AI\")\nprint(\"  - Baseline: Original test dataset\")\nprint(\"  - Drift detection enabled: True\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Baseline data prepared:\n  - Shape: (576, 20)\n  - Features: 20\n  - Samples: 576\n\nMonitoring configuration complete\n  - Monitoring tool: Evidently AI\n  - Baseline: Original test dataset\n  - Drift detection enabled: True\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **7. Use the test data with the deployed model and validate the results (metric) and model monitoring**"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Connect to the model endpoint\npredictor = Predictor(\n    endpoint_name= ENDPOINT_NAME,\n    sagemaker_session= SESSION,\n    serializer= CSVSerializer(),\n    deserializer= CSVDeserializer()\n)\n\nprint(\"Testing model using test (X_test) data...\")\n\n# Get predictions\ny_pred_original = []\nfor i in range(len(X_test)):\n    sample = X_test.iloc[i:i+1].values  # Get sample values\n    pred = predictor.predict(sample)  # Get predictions from deployed model\n    pred_value = float(np.array(pred).flatten()[0])  # Flatten and convert to float\n    y_pred_original.append(1 if pred_value > 0.5 else 0)  # Convert to binary classification\n\naccuracy_original = accuracy_score(y_test, y_pred_original)\n\nprint(f\"\\nResults:\")\nprint(f\"- Accuracy: {accuracy_original:.3f}\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Testing model using test (X_test) data...\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nResults:\n- Accuracy: 0.883\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "REPORT_TYPE = 'original'\nREPORT_S3_PATH = f\"reports/monitoring_report_{REPORT_TYPE}.html\"\n\n# Monitor Model Predictions: X_test\nresults_original = detect_model_drift(\n    test_data= X_test,\n    y_pred= y_pred_original,\n    report_s3_key= REPORT_S3_PATH,\n    predictor= predictor,\n    baseline_data= baseline_data,\n    bucket_name= BUCKET_NAME,\n    s3_client= S3_CLIENT\n)",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "============================================================\nMODEL MONITORING: DRIFT DETECTION\n============================================================\nGenerating baseline predictions from the deployed model...\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nDrift Detection Results:\nTotal features analyzed: 21\n\nTest: Number of Drifted Features\nStatus: SUCCESS\nDescription: The drift is detected for 2 out of 21 features. The test threshold is lt=3.\nParameters: {'condition': {'lt': 3}, 'features': {'prediction': {'stattest': 'Z-test p_value', 'score': 0.163, 'threshold': 0.05, 'detected': False}, 'Attack': {'stattest': 'K-S p_value', 'score': 0.466, 'threshold': 0.05, 'detected': False}, 'Body_Style': {'stattest': 'K-S p_value', 'score': 0.858, 'threshold': 0.05, 'detected': False}, 'Catch_Difficulty': {'stattest': 'chi-square p_value', 'score': 0.184, 'threshold': 0.05, 'detected': False}, 'Color': {'stattest': 'K-S p_value', 'score': 0.549, 'threshold': 0.05, 'detected': False}, 'Defense': {'stattest': 'K-S p_value', 'score': 0.056, 'threshold': 0.05, 'detected': False}, 'Egg_Group_1': {'stattest': 'K-S p_value', 'score': 0.999, 'threshold': 0.05, 'detected': False}, 'Egg_Group_2': {'stattest': 'K-S p_value', 'score': 0.545, 'threshold': 0.05, 'detected': False}, 'Generation': {'stattest': 'K-S p_value', 'score': 0.945, 'threshold': 0.05, 'detected': False}, 'HP': {'stattest': 'K-S p_value', 'score': 0.295, 'threshold': 0.05, 'detected': False}, 'Has_Egg_Group_2': {'stattest': 'Z-test p_value', 'score': 0.077, 'threshold': 0.05, 'detected': False}, 'Has_Type_2': {'stattest': 'Z-test p_value', 'score': 0.002, 'threshold': 0.05, 'detected': True}, 'Height_m': {'stattest': 'K-S p_value', 'score': 0.17, 'threshold': 0.05, 'detected': False}, 'Sp_Atk': {'stattest': 'K-S p_value', 'score': 0.468, 'threshold': 0.05, 'detected': False}, 'Sp_Def': {'stattest': 'K-S p_value', 'score': 0.08, 'threshold': 0.05, 'detected': False}, 'Speed': {'stattest': 'K-S p_value', 'score': 0.217, 'threshold': 0.05, 'detected': False}, 'Total': {'stattest': 'K-S p_value', 'score': 0.053, 'threshold': 0.05, 'detected': False}, 'Type_1': {'stattest': 'K-S p_value', 'score': 0.562, 'threshold': 0.05, 'detected': False}, 'Type_2': {'stattest': 'K-S p_value', 'score': 0.017, 'threshold': 0.05, 'detected': True}, 'Weight_kg': {'stattest': 'K-S p_value', 'score': 0.545, 'threshold': 0.05, 'detected': False}, 'isLegendary': {'stattest': 'Z-test p_value', 'score': 0.634, 'threshold': 0.05, 'detected': False}}}\n\nReport saved to s3://ml-ops-fp/reports/monitoring_report_original.html\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **8. Change at least 2 feature values of the test dataset (you can put in random values or swap 2 features)**"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "print(\"Modifying test data...\")\nX_test_modified = X_test.copy()  # Create a copy for modification\n\n# Change 1\nprint(\"Change 1: Swap column 0 and column 1\")\nX_test_modified.iloc[:, [0, 1]] = X_test_modified.iloc[:, [1, 0]].values\n\n# Change 2\nprint(\"Change 2: Swap column 2 and column 7\")\nX_test_modified.iloc[:, [2, 7]] = X_test_modified.iloc[:, [7, 2]].values\n\n# Change 3\nprint(\"Change 3: Randomizing column 2\")\nX_test_modified.iloc[:, 2] = np.random.randint(50, 150, size=len(X_test_modified))\n\n# Change 4\nprint(\"Change 4: Randomizing column 4\")\nX_test_modified.iloc[:, 4] = np.random.randint(50, 150, size=len(X_test_modified))\n\nprint(\"Test data modified successfully\")\nprint(f\"\\nBefore and After Comparison: Row 0:\")\nprint(f\"Original: {X_test.iloc[0, :10].values}\")\nprint(f\"\\nModified: {X_test_modified.iloc[0, :10].values}\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Modifying test data...\nChange 1: Swap column 0 and column 1\nChange 2: Swap column 2 and column 7\nChange 3: Randomizing column 2\nChange 4: Randomizing column 4\nTest data modified successfully\n\nBefore and After Comparison: Row 0:\nOriginal: [ 6.         18.         -1.57698178 -1.10222852 -1.2190696  -1.06975269\n  0.02599269 -1.12151659 -1.71020758  2.        ]\n\nModified: [ 1.80000000e+01  6.00000000e+00  1.01000000e+02 -1.10222852e+00\n  5.20000000e+01 -1.06975269e+00  2.59926897e-02 -1.57698178e+00\n -1.71020758e+00  2.00000000e+00]\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **9. Use the \"changed\" test data with the deployed model and validate the results (metric) and verify observation with model monitoring.**"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "print(\"Testing model using modified (X_test_modified) data...\")\n\n# Get predictions\ny_pred_modified = []\nfor i in range(len(X_test_modified)):\n    sample = X_test_modified.iloc[i:i+1].values  # Get sample values\n    pred = predictor.predict(sample)  # Get predictions from deployed model\n    pred_value = float(np.array(pred).flatten()[0])  # Flatten and convert to float\n    y_pred_modified.append(1 if pred_value > 0.5 else 0)  # Convert to binary classification\n\naccuracy_modified = accuracy_score(y_test, y_pred_modified)\n\nprint(f\"\\nResults:\")\nprint(f\"- Accuracy: {accuracy_modified:.3f}\")",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Testing model using modified (X_test_modified) data...\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nResults:\n- Accuracy: 0.738\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "REPORT_TYPE = 'modified'\nREPORT_S3_PATH = f\"reports/monitoring_report_{REPORT_TYPE}.html\"\n\n# Monitor Model Predictions: X_test_modified\nresults_original = detect_model_drift(\n    test_data= X_test_modified,\n    y_pred= y_pred_modified,\n    report_s3_key= REPORT_S3_PATH,\n    predictor= predictor,\n    baseline_data= baseline_data,\n    bucket_name= BUCKET_NAME,\n    s3_client= S3_CLIENT\n)",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "============================================================\nMODEL MONITORING: DRIFT DETECTION\n============================================================\nGenerating baseline predictions from the deployed model...\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nDrift Detection Results:\nTotal features analyzed: 21\n\nTest: Number of Drifted Features\nStatus: FAIL\nDescription: The drift is detected for 7 out of 21 features. The test threshold is lt=3.\nParameters: {'condition': {'lt': 3}, 'features': {'prediction': {'stattest': 'Z-test p_value', 'score': 0.0, 'threshold': 0.05, 'detected': True}, 'Attack': {'stattest': 'K-S p_value', 'score': 0.0, 'threshold': 0.05, 'detected': True}, 'Body_Style': {'stattest': 'K-S p_value', 'score': 0.858, 'threshold': 0.05, 'detected': False}, 'Catch_Difficulty': {'stattest': 'chi-square p_value', 'score': 0.184, 'threshold': 0.05, 'detected': False}, 'Color': {'stattest': 'K-S p_value', 'score': 0.549, 'threshold': 0.05, 'detected': False}, 'Defense': {'stattest': 'K-S p_value', 'score': 0.056, 'threshold': 0.05, 'detected': False}, 'Egg_Group_1': {'stattest': 'K-S p_value', 'score': 0.999, 'threshold': 0.05, 'detected': False}, 'Egg_Group_2': {'stattest': 'K-S p_value', 'score': 0.545, 'threshold': 0.05, 'detected': False}, 'Generation': {'stattest': 'K-S p_value', 'score': 0.945, 'threshold': 0.05, 'detected': False}, 'HP': {'stattest': 'K-S p_value', 'score': 0.295, 'threshold': 0.05, 'detected': False}, 'Has_Egg_Group_2': {'stattest': 'Z-test p_value', 'score': 0.077, 'threshold': 0.05, 'detected': False}, 'Has_Type_2': {'stattest': 'Z-test p_value', 'score': 0.002, 'threshold': 0.05, 'detected': True}, 'Height_m': {'stattest': 'K-S p_value', 'score': 0.17, 'threshold': 0.05, 'detected': False}, 'Sp_Atk': {'stattest': 'K-S p_value', 'score': 0.468, 'threshold': 0.05, 'detected': False}, 'Sp_Def': {'stattest': 'K-S p_value', 'score': 0.005, 'threshold': 0.05, 'detected': True}, 'Speed': {'stattest': 'K-S p_value', 'score': 0.217, 'threshold': 0.05, 'detected': False}, 'Total': {'stattest': 'K-S p_value', 'score': 0.0, 'threshold': 0.05, 'detected': True}, 'Type_1': {'stattest': 'K-S p_value', 'score': 0.0, 'threshold': 0.05, 'detected': True}, 'Type_2': {'stattest': 'K-S p_value', 'score': 0.0, 'threshold': 0.05, 'detected': True}, 'Weight_kg': {'stattest': 'K-S p_value', 'score': 0.545, 'threshold': 0.05, 'detected': False}, 'isLegendary': {'stattest': 'Z-test p_value', 'score': 0.634, 'threshold': 0.05, 'detected': False}}}\n\nReport saved to s3://ml-ops-fp/reports/monitoring_report_modified.html\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Shutdown cells"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\"\"\"\nStop spark session and associated Athena Spark session\n\"\"\"\n\nfrom IPython import get_ipython as _get_ipython\n_get_ipython().user_ns[\"spark\"].stop()",
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}