{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Machine Learning Operations Final Project**\n",
        "Group Members:\n",
        "- **Bradley Stoller**\n",
        "- **Samuel Martinez Koss**\n",
        "- **Xigang Zhang**\n",
        "- **Zhiwei Guo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **General Notebook Configurations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "General configuration complete\n"
          ]
        },
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "RANDOM_SEED = 42\n",
        "\n",
        "print('General configuration complete')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **AWS Configurations**\n",
        "AWS setup: credentials, S3 buckets, IAM roles, and service clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sagemaker.config INFO - Fetched defaults config from location: /etc/xdg/sagemaker/config.yaml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
          ]
        },
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AWS Configuration loaded\n",
            "- Region: us-east-2\n",
            "- Bucket: ml-ops-fp\n",
            "- Role ARN: arn:aws:iam::116527261367:role/SageMakerExecutionRole\n"
          ]
        }
      ],
      "source": [
        "# AWS Credentials\n",
        "AWS_ACCESS_KEY = 'REMOVEDRWIMQ423ZX2EREMOVED'\n",
        "AWS_SECRET_KEY = 'REMOVED5KRZgS8+oMPZCbNm3/0yBs0BwFlbx1yHREMOVED'\n",
        "\n",
        "# S3 Configuration\n",
        "BUCKET_NAME = 'ml-ops-fp'\n",
        "PREFIX = 'pokemon-classification'\n",
        "\n",
        "# IAM Role\n",
        "ROLE = 'REMOVED84002890:role/service-role/AmazonSageMaker-ExecutionRole-20241120TREMOVED'\n",
        "ROLE_ARN = 'arn:aws:iam::116527261367:role/SageMakerExecutionRole'\n",
        "\n",
        "# Initialize SageMaker Session and Boto3 Clients\n",
        "import sagemaker\n",
        "import boto3\n",
        "\n",
        "SESSION = sagemaker.Session()\n",
        "REGION = SESSION.boto_region_name\n",
        "\n",
        "SM_CLIENT = boto3.client('sagemaker')\n",
        "S3_CLIENT = boto3.client('s3')\n",
        "\n",
        "print(f\"AWS Configuration loaded\")\n",
        "print(f\"- Region: {REGION}\")\n",
        "print(f\"- Bucket: {BUCKET_NAME}\")\n",
        "print(f\"- Role ARN: {ROLE_ARN}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Import Library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install Non-Default Sagemaker Studio Packages\n",
        "- `imbalanced-learn`\n",
        "- `mlflow`\n",
        "- `statsmodels`\n",
        "- `evidently`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All packages installed\n"
          ]
        },
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Install import libraries\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Install imbalanced-learn, mlflow, statsmodels, and evidently\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"imbalanced-learn\"])\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"mlflow\"])\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"statsmodels\"])\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"evidently\"])\n",
        "\n",
        "print(\"All packages installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import all necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All libraries imported\n"
          ]
        }
      ],
      "source": [
        "# Core Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import joblib\n",
        "import tarfile\n",
        "import warnings\n",
        "from io import StringIO\n",
        "from collections import Counter\n",
        "from itertools import product\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Data Processing & ML\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, roc_curve, auc,\n",
        "    precision_recall_curve, accuracy_score, precision_score,\n",
        "    recall_score, f1_score\n",
        ")\n",
        "\n",
        "# Imbalanced Learning\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Statistical Analysis\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import randint, uniform\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "\n",
        "# MLflow\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow.models import infer_signature\n",
        "\n",
        "# SageMaker\n",
        "import sagemaker\n",
        "import boto3\n",
        "from sagemaker.automl.automl import AutoML\n",
        "from sagemaker.sklearn.model import SKLearnModel\n",
        "from sagemaker.xgboost import XGBoostModel\n",
        "from sagemaker.predictor import Predictor\n",
        "from sagemaker.serializers import CSVSerializer\n",
        "from sagemaker.deserializers import JSONDeserializer, CSVDeserializer\n",
        "from sagemaker.model_monitor import DefaultModelMonitor, MonitoringExecution\n",
        "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
        "\n",
        "# Evidently\n",
        "import base64\n",
        "from evidently.legacy.test_suite import TestSuite\n",
        "from evidently.legacy.tests import TestNumberOfDriftedColumns\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All libraries imported\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Function Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def clean_data(data):\n",
        "    \"\"\"Clearn the data to be used for modeling. \"\"\"\n",
        "\n",
        "    # Copy data to avoid modifying original\n",
        "    data_copy = data.copy()\n",
        "\n",
        "    # Drop columns irrelevant to mega evolutions\n",
        "    data_copy = data_copy.drop(columns=[\n",
        "        'Name',\n",
        "        'Number',\n",
        "        'hasGender',\n",
        "        'Pr_Male',\n",
        "    ])\n",
        "\n",
        "    # Create binary indicators for optional secondary attributes\n",
        "    data_copy['Has_Type_2'] = data_copy['Type_2'].notna().astype(int)\n",
        "    data_copy['Has_Egg_Group_2'] = data_copy['Egg_Group_2'].notna().astype(int)\n",
        "\n",
        "    # Bin Catch_Rate into difficulty categories (higher rate = easier to catch)\n",
        "    data_copy['Catch_Difficulty'] = pd.cut(\n",
        "        data_copy['Catch_Rate'],\n",
        "        bins=3,\n",
        "        labels=['Hard', 'Medium', 'Easy']\n",
        "    ).astype(str)  # Convert to string immediately to avoid categorical issues\n",
        "\n",
        "    # Separate features and target (drop original Catch_Rate, keep binned version)\n",
        "    features = data_copy.drop(['Catch_Rate', 'hasMegaEvolution'], axis=1)\n",
        "    target = data_copy['hasMegaEvolution']\n",
        "\n",
        "    return features, target\n",
        "\n",
        "def scale_and_encode(X_train, X_test):\n",
        "    \"\"\"Scale and encode the data for modeling. \"\"\"\n",
        "\n",
        "    # Identify integer colums that need conversion\n",
        "    num_cols = [\n",
        "        c for c in X_train.select_dtypes('integer').columns\n",
        "        if len(X_train[c].unique()) > 10\n",
        "    ]\n",
        "    X_train = X_train.astype({c: 'float32' for c in num_cols})\n",
        "    X_test = X_test.astype({c: 'float32' for c in num_cols})\n",
        "\n",
        "    # Standardize interval features\n",
        "    num_cols = X_train.select_dtypes(exclude=['bool', 'object', 'string', 'int64']).columns\n",
        "    for col in num_cols:\n",
        "        scaler = StandardScaler()\n",
        "        X_train[col] = scaler.fit_transform(X_train[[col]])\n",
        "        X_test[col] = scaler.transform(X_test[[col]])\n",
        "\n",
        "    # Encode categorical features using a label encoder\n",
        "    cat_cols = X_train.select_dtypes(include=['object', 'bool']).columns\n",
        "    for col in cat_cols:\n",
        "        X_train[col] = X_train[col].astype(str).replace('nan', 'missing')\n",
        "        X_test[col] = X_test[col].astype(str).replace('nan', 'missing')\n",
        "\n",
        "        le = LabelEncoder()\n",
        "        X_train[col] = le.fit_transform(X_train[col])\n",
        "\n",
        "        # Ensure that unseen columns are encoded as -1\n",
        "        test_x_col = []\n",
        "        for val in X_test[col]:\n",
        "            if val in le.classes_:\n",
        "                test_x_col.append(le.transform([val])[0])\n",
        "            else:\n",
        "                test_x_col.append(-1)\n",
        "        X_test[col] = test_x_col\n",
        "\n",
        "    return X_train, X_test\n",
        "\n",
        "def prepare_data(data, verbose=False):\n",
        "    \"\"\"Clean the data, split the data, and apply SMOTE for modeling. \"\"\"\n",
        "\n",
        "    # Remove unnecessary cols, feature engineering\n",
        "    X, y = clean_data(data)\n",
        "\n",
        "    # Split data into train and test\n",
        "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify= y\n",
        "    )\n",
        "\n",
        "    # Scale interval features and encode categorical features\n",
        "    X_train, X_test = scale_and_encode(X_train_raw, X_test_raw)\n",
        "\n",
        "    # Apply SMOTE to handle class imbalance\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    if verbose:\n",
        "        # Check class distribution before SMOTE\n",
        "        print(\"\\nClass distribution before SMOTE:\")\n",
        "        print(Counter(y_train))\n",
        "\n",
        "        # Check class distribution after SMOTE\n",
        "        print(\"\\nClass distribution after SMOTE:\")\n",
        "        print(Counter(y_train_resampled))\n",
        "\n",
        "    return X_train_resampled, X_test, y_train_resampled, y_test, X_train, y_train\n",
        "\n",
        "def log_model_metrics(y_actual, y_pred):\n",
        "    \"\"\"Setup logging configurations for MLflow usage. \"\"\"\n",
        "\n",
        "    mlflow.log_metric('accuracy', accuracy_score(y_actual, y_pred))\n",
        "    mlflow.log_metric('precision', precision_score(y_actual, y_pred))\n",
        "    mlflow.log_metric('recall', recall_score(y_actual, y_pred))\n",
        "    mlflow.log_metric('f1', f1_score(y_actual, y_pred))\n",
        "\n",
        "def confusion_matrix_plot(y_actual, y_pred):\n",
        "    \"\"\"Plot a confusion matrix of the results for MLflow. \"\"\"\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_actual, y_pred)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "    # Use a color palette that clearly differentiates cells (custom or built-in)\n",
        "    cmap = sns.color_palette(\"RdYlBu_r\", as_cmap=True)\n",
        "\n",
        "    # Draw heatmap with square cells and no colorbar for cleaner look\n",
        "    sns.heatmap(\n",
        "        conf_matrix,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap=cmap,\n",
        "        xticklabels=['No Mega', 'Has Mega'],\n",
        "        yticklabels=['No Mega', 'Has Mega'],\n",
        "        cbar=False,\n",
        "        square=True,\n",
        "        linewidths=1,\n",
        "        linecolor='gray',\n",
        "        ax=ax\n",
        "    )\n",
        "\n",
        "    ax.set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Actual', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Mega Evolution Prediction Confusion Matrix', fontsize=14, pad=20)\n",
        "\n",
        "    # Add refined annotations inside cells - positions adjusted for better spacing\n",
        "    # Get bounding box coordinates of each cell for placement reference\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            text = \"\"\n",
        "            if i == 0 and j == 0:\n",
        "                text = 'True Negatives\\n(Correctly predicted\\nno Mega Evolution)'\n",
        "                xytext = (j + 0.5, i + 0.7)\n",
        "            elif i == 0 and j == 1:\n",
        "                text = 'False Positives\\n(Incorrectly predicted\\nMega Evolution)'\n",
        "                xytext = (j + 0.5, i + 0.7)\n",
        "            elif i == 1 and j == 0:\n",
        "                text = 'False Negatives\\n(Missed actual\\nMega Evolution)'\n",
        "                xytext = (j + 0.5, i + 0.7)\n",
        "            elif i == 1 and j == 1:\n",
        "                text = 'True Positives\\n(Correctly predicted\\nMega Evolution)'\n",
        "                xytext = (j + 0.5, i + 0.7)\n",
        "\n",
        "            ax.text(\n",
        "                xytext[0], xytext[1], text,\n",
        "                ha='center',\n",
        "                va='center',\n",
        "                fontsize=9,\n",
        "                color='black',\n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.7)\n",
        "            )\n",
        "\n",
        "    fig.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def roc_curve_plot(y_actual, y_prob):\n",
        "    \"\"\"Plot a ROC Curve plot of the results for MLflow. \"\"\"\n",
        "\n",
        "    # Compute ROC curve and AUC\n",
        "    fpr, tpr, _ = roc_curve(y_actual, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.plot(fpr, tpr, lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    ax.plot([0, 1], [0, 1], lw=2, linestyle='--')\n",
        "\n",
        "    ax.set_xlim([0.0, 1.0])\n",
        "    ax.set_ylim([0.0, 1.05])\n",
        "    ax.set_xlabel('False Positive Rate')\n",
        "    ax.set_ylabel('True Positive Rate')\n",
        "    ax.set_title('Receiver Operating Characteristic')\n",
        "\n",
        "    ax.legend(loc=\"lower right\")\n",
        "    return fig\n",
        "\n",
        "def precision_recall_plot(y_actual, y_prob):\n",
        "    \"\"\"Plot a precision-recall plot of the results for MLflow. \"\"\"\n",
        "\n",
        "    # Compute precision-recall values\n",
        "    precision, recall, _ = precision_recall_curve(y_actual, y_prob)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.plot(recall, precision, lw=2)\n",
        "    ax.set_xlabel(\"Recall\")\n",
        "    ax.set_ylabel(\"Precision\")\n",
        "    ax.set_title(\"Precision-Recall Curve\")\n",
        "\n",
        "    return fig\n",
        "\n",
        "def feature_importance_plot(model, features):    \n",
        "    \"\"\"Plot features importances for MLflow. \"\"\"\n",
        "\n",
        "    importances = model.feature_importances_\n",
        "    feature_importance_dict = {name: imp for name, imp in zip(features, importances)}\n",
        "    sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Prepare top 10 features\n",
        "    top_n = min(10, len(sorted_features))\n",
        "    feature_names_plot = [name for name, _ in sorted_features[:top_n]]\n",
        "    importance_values = [imp for _, imp in sorted_features[:top_n]]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    ax.set_title(\"Feature Importances\")\n",
        "\n",
        "    ax.barh(range(top_n), importance_values, align=\"center\")\n",
        "    ax.set_yticks(range(top_n))\n",
        "    ax.set_yticklabels(feature_names_plot)\n",
        "    ax.invert_yaxis()  # Highest importance at the top\n",
        "    ax.set_xlabel(\"Importance\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def log_model_plots(y_actual, y_pred, y_prob, model, features):\n",
        "    \"\"\"Set up logging for plots used by MLflow. \"\"\"\n",
        "\n",
        "    fig = confusion_matrix_plot(y_actual, y_pred)\n",
        "    mlflow.log_figure(fig, 'confusion_matrix.png')\n",
        "    plt.close(fig)\n",
        "\n",
        "    fig = roc_curve_plot(y_actual, y_prob)\n",
        "    mlflow.log_figure(fig, 'roc_curve.png')\n",
        "    plt.close(fig)\n",
        "\n",
        "    fig = precision_recall_plot(y_actual, y_prob)\n",
        "    mlflow.log_figure(fig, 'precision_recall.png')\n",
        "    plt.close(fig)\n",
        "\n",
        "    fig = feature_importance_plot(model, features)\n",
        "    mlflow.log_figure(fig, 'feature_importance.png')\n",
        "    plt.close(fig)\n",
        "\n",
        "def mlflow_pipeline(features, target, random_seed= RANDOM_SEED, run_name= 'test_run', experiment_name= 'Default', **model_params):\n",
        "    \"\"\"Create the MLflow experiment pipeline. \"\"\"\n",
        "\n",
        "    warnings.filterwarnings('ignore')\n",
        "    np.random.seed(random_seed)\n",
        "    mlflow.set_tracking_uri('file:./mlruns')\n",
        "    mlflow.set_experiment(experiment_name)\n",
        "\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "        gb_model = GradientBoostingClassifier(random_state=random_seed, **model_params)\n",
        "\n",
        "        gb_model.fit(features, target)\n",
        "        y_pred = gb_model.predict(features)\n",
        "        y_prob = gb_model.predict_proba(features)[:, 1]\n",
        "\n",
        "        mlflow.log_params(model_params)\n",
        "        log_model_metrics(target, y_pred)\n",
        "        log_model_plots(target, y_pred, y_prob, gb_model, features.columns)\n",
        "\n",
        "        signature = infer_signature(features, gb_model.predict(features))\n",
        "        mlflow.sklearn.log_model(\n",
        "            gb_model, name=run_name[:5], signature=signature\n",
        "        )\n",
        "\n",
        "def sample_params(param_dist, n_samples=5, random_state=None):\n",
        "    \"\"\"Get the sample parameters for usage in MLflow. \"\"\"\n",
        "\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    samples = []\n",
        "    for _ in range(n_samples):\n",
        "        sample = {}\n",
        "        for param, dist in param_dist.items():\n",
        "            if hasattr(dist, 'rvs'):\n",
        "                val = dist.rvs(random_state=rng)\n",
        "                if dist.dist.name == 'randint':\n",
        "                    val = int(val)\n",
        "                sample[param] = val\n",
        "            else:\n",
        "                sample[param] = rng.choice(dist)\n",
        "        samples.append(sample)\n",
        "    return samples\n",
        "\n",
        "def upload_mlflow(run_id, experiment_id, bucket_name=BUCKET_NAME, s3_prefix=\"MLflow/best-run\"):\n",
        "    \"\"\"Upload the best MLflow run files to S3. \"\"\"\n",
        "    \n",
        "    # Path to the specific run\n",
        "    local_run_path = f\"./mlruns/{experiment_id}/{run_id}\"\n",
        "    \n",
        "    if not os.path.exists(local_run_path):\n",
        "        print(f\"Run directory not found: {local_run_path}\")\n",
        "        return None\n",
        "    \n",
        "    s3_path = f\"s3://{bucket_name}/{s3_prefix}/\"\n",
        "    print(f\"Uploading best run {run_id} to {s3_path}...\")\n",
        "    \n",
        "    # Upload all files in the run directory\n",
        "    file_count = 0\n",
        "    for root, dirs, files in os.walk(local_run_path):\n",
        "        for file in files:\n",
        "            local_file = os.path.join(root, file)\n",
        "            relative_path = os.path.relpath(local_file, local_run_path)\n",
        "            s3_key = f\"{s3_prefix}/{relative_path}\"\n",
        "            \n",
        "            S3_CLIENT.upload_file(local_file, bucket_name, s3_key)\n",
        "            file_count += 1\n",
        "    \n",
        "    print(f\"Successfully uploaded {file_count} files to {s3_path}\")\n",
        "\n",
        "def detect_model_drift(test_data, y_pred, report_s3_key, predictor, baseline_data, bucket_name, s3_client):\n",
        "    \"\"\"Detect model drift by comparing test data predictions against baseline. \"\"\"\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"MODEL MONITORING: DRIFT DETECTION\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Add predictions to the baseline data using the deployed model\n",
        "    print(\"Generating baseline predictions from the deployed model...\")\n",
        "    baseline_predictions = []\n",
        "\n",
        "    for i in range(len(baseline_data)):\n",
        "        sample = baseline_data.iloc[i:i+1].values\n",
        "        pred = predictor.predict(sample)\n",
        "        pred_value = float(np.array(pred).flatten()[0])\n",
        "        baseline_predictions.append(1 if pred_value > 0.5 else 0)\n",
        "    \n",
        "    baseline_with_predictions = baseline_data.copy()\n",
        "    baseline_with_predictions['prediction'] = baseline_predictions\n",
        "    \n",
        "    current_with_predictions = test_data.copy()\n",
        "    current_with_predictions['prediction'] = y_pred\n",
        "    \n",
        "    # Create Evidently AI test suite for drift detection\n",
        "    test_suite = TestSuite(tests=[\n",
        "        TestNumberOfDriftedColumns(lt=3),\n",
        "    ])\n",
        "    \n",
        "    # Run drift detection\n",
        "    test_suite.run(reference_data=baseline_with_predictions, current_data=current_with_predictions)\n",
        "    \n",
        "    # Get results\n",
        "    results = test_suite.as_dict()\n",
        "    \n",
        "    # Print the drift summary\n",
        "    print(\"\\nDrift Detection Results:\")\n",
        "    print(f\"Total features analyzed: {baseline_with_predictions.shape[1]}\")\n",
        "    \n",
        "    # Extract the test results\n",
        "    for test in results['tests']:\n",
        "        print(f\"\\nTest: {test['name']}\")\n",
        "        print(f\"Status: {test['status']}\")\n",
        "        if 'description' in test:\n",
        "            print(f\"Description: {test['description']}\")\n",
        "        if 'parameters' in test:\n",
        "            print(f\"Parameters: {test['parameters']}\")\n",
        "    \n",
        "    # Save the Drift Report\n",
        "    s3_client.put_object(\n",
        "        Bucket=bucket_name,\n",
        "        Key=report_s3_key,\n",
        "        Body=test_suite.get_html(),\n",
        "        ContentType='text/html'\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nReport saved to s3://{bucket_name}/{report_s3_key}\")\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **1. Choose a dataset that has an outcome (predictive) variable**\n",
        "For our dataset, we chose to use a variety of information about pokemon characters, with the predictive variable being `hasMegaEvolution`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Shape: (721, 23)\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 721 entries, 0 to 720\n",
            "Data columns (total 23 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Number            721 non-null    int64  \n",
            " 1   Name              721 non-null    object \n",
            " 2   Type_1            721 non-null    object \n",
            " 3   Type_2            350 non-null    object \n",
            " 4   Total             721 non-null    int64  \n",
            " 5   HP                721 non-null    int64  \n",
            " 6   Attack            721 non-null    int64  \n",
            " 7   Defense           721 non-null    int64  \n",
            " 8   Sp_Atk            721 non-null    int64  \n",
            " 9   Sp_Def            721 non-null    int64  \n",
            " 10  Speed             721 non-null    int64  \n",
            " 11  Generation        721 non-null    int64  \n",
            " 12  isLegendary       721 non-null    bool   \n",
            " 13  Color             721 non-null    object \n",
            " 14  hasGender         721 non-null    bool   \n",
            " 15  Pr_Male           644 non-null    float64\n",
            " 16  Egg_Group_1       721 non-null    object \n",
            " 17  Egg_Group_2       191 non-null    object \n",
            " 18  hasMegaEvolution  721 non-null    bool   \n",
            " 19  Height_m          721 non-null    float64\n",
            " 20  Weight_kg         721 non-null    float64\n",
            " 21  Catch_Rate        721 non-null    int64  \n",
            " 22  Body_Style        721 non-null    object \n",
            "dtypes: bool(3), float64(3), int64(10), object(7)\n",
            "memory usage: 114.9+ KB\n"
          ]
        },
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.datanotebooks+parquet+snappy": "{\"data\":\"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\"}",
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number</th>\n",
              "      <th>Name</th>\n",
              "      <th>Type_1</th>\n",
              "      <th>Type_2</th>\n",
              "      <th>Total</th>\n",
              "      <th>HP</th>\n",
              "      <th>Attack</th>\n",
              "      <th>Defense</th>\n",
              "      <th>Sp_Atk</th>\n",
              "      <th>Sp_Def</th>\n",
              "      <th>Speed</th>\n",
              "      <th>Generation</th>\n",
              "      <th>isLegendary</th>\n",
              "      <th>Color</th>\n",
              "      <th>hasGender</th>\n",
              "      <th>Pr_Male</th>\n",
              "      <th>Egg_Group_1</th>\n",
              "      <th>Egg_Group_2</th>\n",
              "      <th>hasMegaEvolution</th>\n",
              "      <th>Height_m</th>\n",
              "      <th>Weight_kg</th>\n",
              "      <th>Catch_Rate</th>\n",
              "      <th>Body_Style</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Bulbasaur</td>\n",
              "      <td>Grass</td>\n",
              "      <td>Poison</td>\n",
              "      <td>318</td>\n",
              "      <td>45</td>\n",
              "      <td>49</td>\n",
              "      <td>49</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>Green</td>\n",
              "      <td>True</td>\n",
              "      <td>0.875</td>\n",
              "      <td>Monster</td>\n",
              "      <td>Grass</td>\n",
              "      <td>False</td>\n",
              "      <td>0.71</td>\n",
              "      <td>6.9</td>\n",
              "      <td>45</td>\n",
              "      <td>quadruped</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Ivysaur</td>\n",
              "      <td>Grass</td>\n",
              "      <td>Poison</td>\n",
              "      <td>405</td>\n",
              "      <td>60</td>\n",
              "      <td>62</td>\n",
              "      <td>63</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>Green</td>\n",
              "      <td>True</td>\n",
              "      <td>0.875</td>\n",
              "      <td>Monster</td>\n",
              "      <td>Grass</td>\n",
              "      <td>False</td>\n",
              "      <td>0.99</td>\n",
              "      <td>13.0</td>\n",
              "      <td>45</td>\n",
              "      <td>quadruped</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Venusaur</td>\n",
              "      <td>Grass</td>\n",
              "      <td>Poison</td>\n",
              "      <td>525</td>\n",
              "      <td>80</td>\n",
              "      <td>82</td>\n",
              "      <td>83</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>Green</td>\n",
              "      <td>True</td>\n",
              "      <td>0.875</td>\n",
              "      <td>Monster</td>\n",
              "      <td>Grass</td>\n",
              "      <td>True</td>\n",
              "      <td>2.01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>45</td>\n",
              "      <td>quadruped</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Charmander</td>\n",
              "      <td>Fire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>309</td>\n",
              "      <td>39</td>\n",
              "      <td>52</td>\n",
              "      <td>43</td>\n",
              "      <td>60</td>\n",
              "      <td>50</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>Red</td>\n",
              "      <td>True</td>\n",
              "      <td>0.875</td>\n",
              "      <td>Monster</td>\n",
              "      <td>Dragon</td>\n",
              "      <td>False</td>\n",
              "      <td>0.61</td>\n",
              "      <td>8.5</td>\n",
              "      <td>45</td>\n",
              "      <td>bipedal_tailed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Charmeleon</td>\n",
              "      <td>Fire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>405</td>\n",
              "      <td>58</td>\n",
              "      <td>64</td>\n",
              "      <td>58</td>\n",
              "      <td>80</td>\n",
              "      <td>65</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>Red</td>\n",
              "      <td>True</td>\n",
              "      <td>0.875</td>\n",
              "      <td>Monster</td>\n",
              "      <td>Dragon</td>\n",
              "      <td>False</td>\n",
              "      <td>1.09</td>\n",
              "      <td>19.0</td>\n",
              "      <td>45</td>\n",
              "      <td>bipedal_tailed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Number        Name Type_1  ... Weight_kg  Catch_Rate      Body_Style\n",
              "0       1   Bulbasaur  Grass  ...       6.9          45       quadruped\n",
              "1       2     Ivysaur  Grass  ...      13.0          45       quadruped\n",
              "2       3    Venusaur  Grass  ...     100.0          45       quadruped\n",
              "3       4  Charmander   Fire  ...       8.5          45  bipedal_tailed\n",
              "4       5  Charmeleon   Fire  ...      19.0          45  bipedal_tailed\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DATA_KEY = 'pokemon-data/pokemon.csv'\n",
        "S3_PATH = f's3://{BUCKET_NAME}/{DATA_KEY}'\n",
        "df = pd.read_csv(S3_PATH)\n",
        "print(f\"Dataset Shape: {df.shape}\\n\")\n",
        "df.info()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb267678",
      "metadata": {},
      "source": [
        "An EDA of the dataset can be found in the `eda.ipynb` file in the github. In this notebook, we will move forward with the dataset from here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **2. Split that into train and test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Features: 20\n",
            "X_train shape: (1078, 20)\n",
            "X_test shape: (145, 20)\n",
            "y_train shape: (1078,)\n",
            "y_test shape: (145,)\n"
          ]
        },
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test, X_train_raw, y_train_raw = prepare_data(df)\n",
        "\n",
        "print(f\"Number of Features: {len(X_train.columns)}\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "001fd8a4",
      "metadata": {},
      "source": [
        "As we can see, the model has been appropriately split, with a 20% test size. As such, we can move forward with the modeling steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **3. Define a metric to evaluate a machine learning model**\n",
        "Since our model will be a binary classifier, we will use `accuracy` as the primary metric to evaluate our model. We feel that accuracy provides the most balanced representation of both classes (after applying SMOTE). Additionally, accuracy is easy to interpret with regards to pokemon mega evolution detection rates. Additionally, it is further appropriate since cost of false positives and false negatives are equal in this use case.\n",
        "\n",
        "However, in MLflow, we will log both `accuracy` and `F1-score` in the `log_model_metrics()` function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **4. Build a pipeline using Airflow or MLflow or your platform pipeline to train a machine learning model using the train dataset (use AutoML to refine the category of algorithms).**\n",
        "For our workflow, we will first use AWS AutoML to determine the optimal algorithm category, and then MLflow as the pipeline for training our machine learning model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4a. Use AWS AutoML to determine the optimal algorithm category\n",
        "In order to use AWS AutoML, we will first upload our training data to S3, and then use it to with the AutoML model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data uploaded to S3\n",
            "- s3://ml-ops-fp/automl/input/pokemon_train.csv\n"
          ]
        }
      ],
      "source": [
        "# Combine the training data\n",
        "train_df = pd.concat([\n",
        "    pd.DataFrame(X_train, columns= X_train.columns if hasattr(X_train, 'columns') else None),\n",
        "    pd.Series(y_train, name= 'hasMegaEvolution')\n",
        "], axis= 1)\n",
        "\n",
        "# Save it locally and then upload it to S3\n",
        "train_df.to_csv('pokemon_train.csv', index= False)\n",
        "\n",
        "S3_CLIENT.upload_file('pokemon_train.csv', BUCKET_NAME, 'automl/input/pokemon_train.csv')\n",
        "\n",
        "print(\"Data uploaded to S3\")\n",
        "print(f\"- s3://{BUCKET_NAME}/automl/input/pokemon_train.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With AWS AutoML, we will try seven candidate algorithms, allotting only 3 minutes (180 seconds) for each candidate or 21 total minutes (1,260 seconds) for cost minimization. However, these should still provide enough signal to determine the best algorithm category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting AutoML job...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AutoML job started: pokemon--2025-12-08-19-02-49-681\n"
          ]
        },
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Set the training data location\n",
        "TRAIN_S3_PATH = f's3://{BUCKET_NAME}/automl/input/pokemon_train.csv'\n",
        "OUTPUT_S3_PATH = f's3://{BUCKET_NAME}/automl/output'\n",
        "\n",
        "# Create an AWS AutoML job\n",
        "timestamp = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n",
        "automl = AutoML(\n",
        "    role= ROLE_ARN,\n",
        "    target_attribute_name= 'hasMegaEvolution',\n",
        "    output_path= OUTPUT_S3_PATH,\n",
        "    base_job_name= 'pokemon-automl',\n",
        "    sagemaker_session= SESSION,\n",
        "    problem_type= 'BinaryClassification',\n",
        "    max_candidates= 7,\n",
        "    max_runtime_per_training_job_in_seconds= 180,\n",
        "    total_job_runtime_in_seconds= 1260,\n",
        "    job_objective= {'MetricName': 'Accuracy'},\n",
        "    mode= 'HYPERPARAMETER_TUNING'\n",
        ")\n",
        "\n",
        "# Start the AutoML job\n",
        "print(\"Starting AutoML job...\")\n",
        "automl.fit(\n",
        "    inputs= TRAIN_S3_PATH,\n",
        "    wait= False,\n",
        "    logs= False\n",
        ")\n",
        "\n",
        "job_name = automl.current_job_name\n",
        "print(f\"AutoML job started: {job_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job Name: pokemon--2025-12-08-19-02-49-681\n",
            "Status: Completed\n"
          ]
        }
      ],
      "source": [
        "# Check AutoML status\n",
        "status = automl.describe_auto_ml_job()\n",
        "\n",
        "print(f\"Job Name: {status['AutoMLJobName']}\")\n",
        "print(f\"Status: {status['AutoMLJobStatus']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "BEST MODEL HYPERPARAMETERS\n",
            "======================================================================\n",
            "\n",
            "Model: pokemon--2025-12-08-19-02-49-62u-003-c9d165ab\n",
            "Accuracy: 0.9731 (97.31%)\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Hyperparameters:\n",
            "  processor_module: candidate_data_processors.dpp4\n",
            "  sagemaker_program: candidate_data_processors.trainer\n",
            "  sagemaker_submit_directory: /opt/ml/input/data/code\n",
            "\n",
            "Hyperparameters:\n",
            "  max_depth: 4\n",
            "  eta: 0.6641367908850111\n",
            "  num_round: 364\n",
            "\n",
            "  All Hyperparameters:\n",
            "    _kfold: 5\n",
            "    _tuning_objective_metric: validation:accuracy\n",
            "    alpha: 1.5323566593501716e-06\n",
            "    colsample_bytree: 0.9597047988623544\n",
            "    eval_metric: accuracy,f1_binary,auc,balanced_accuracy,precision,recall,logloss\n",
            "    gamma: 0.00035887647058464487\n",
            "    lambda: 0.9645996772792648\n",
            "    min_child_weight: 0.002811123203178802\n",
            "    objective: binary:logistic\n",
            "    subsample: 0.7488351445742566\n"
          ]
        }
      ],
      "source": [
        "# Get best candidate only\n",
        "best = automl.best_candidate()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"BEST MODEL HYPERPARAMETERS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "name = best['CandidateName']\n",
        "metric = best['FinalAutoMLJobObjectiveMetric']['Value']\n",
        "\n",
        "print(f\"\\nModel: {name}\")\n",
        "print(f\"Accuracy: {metric:.4f} ({metric*100:.2f}%)\")\n",
        "print(f\"\\n{'='*70}\")\n",
        "\n",
        "# Get training job details\n",
        "for step in best.get('CandidateSteps', []):\n",
        "    if step['CandidateStepType'] == 'AWS::SageMaker::TrainingJob':\n",
        "        training_job_name = step['CandidateStepArn'].split('/')[-1]\n",
        "        \n",
        "        try:\n",
        "            training_job = SM_CLIENT.describe_training_job(\n",
        "                TrainingJobName= training_job_name\n",
        "            )\n",
        "            \n",
        "            hyperparams = training_job.get('HyperParameters', {})\n",
        "            \n",
        "            # Extract algorithm details\n",
        "            print(f\"\\nHyperparameters:\")\n",
        "            \n",
        "            # Look for key parameters that indicate the algorithm\n",
        "            key_params = [\n",
        "                'predictor_type', 'algorithm', 'estimator', \n",
        "                'max_depth', 'n_estimators', 'learning_rate',\n",
        "                'booster', 'tree_method', 'model_type', 'eta', 'num_round'\n",
        "            ]\n",
        "            \n",
        "            algorithm_found = False\n",
        "            for param in key_params:\n",
        "                if param in hyperparams:\n",
        "                    print(f\"  {param}: {hyperparams[param]}\")\n",
        "                    algorithm_found = True\n",
        "            \n",
        "            # If specific params found, print all\n",
        "            if algorithm_found:\n",
        "                print(f\"\\n  All Hyperparameters:\")\n",
        "                for key, value in sorted(hyperparams.items()):\n",
        "                    if key not in key_params:\n",
        "                        print(f\"    {key}: {value}\")\n",
        "            else:\n",
        "                # Print everything if we didn't find specific indicators\n",
        "                for key, value in sorted(hyperparams.items()):\n",
        "                    print(f\"  {key}: {value}\")\n",
        "                    \n",
        "        except Exception as e:\n",
        "            print(f\"  Error getting training job: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As seen in the AutoML output above, the hyperparameters of the best model are those used in gradient boosting algorithms. As such, since AutoML has told us that gradient boosting (XG-Boost) is the best algorithm category, we can move forward with our experimentation as to the most optimal XG-Boost hyperparameters with MLflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4b. Use MLflow to create a pipeline for training a machine learning model\n",
        "Since we know from AWS AutoML that the best algorithm is Gradient Boosting (XG-Boost), we will run expriments via a MLflow pipeline to determine the optimal set of hyperparameters. Note: since this notebook was created in Sagemaker for AWS AutoML use, MLflow must be used locally since Sagemaker does not support server MLflow usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "PARAM_DIST = {\n",
        "    'n_estimators': [2, 3, 5, 7],\n",
        "    'learning_rate': uniform(0.01, 0.1),\n",
        "    'max_depth': randint(2, 4),\n",
        "    'min_samples_split': randint(5, 20)\n",
        "}\n",
        "random_grid = sample_params(\n",
        "    PARAM_DIST, \n",
        "    n_samples= 10, \n",
        "    random_state= RANDOM_SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tracking URI: file:./mlruns\n",
            "Experiment: <Experiment: artifact_location='file:///home/sagemaker-user/mlruns/504153010705164362', creation_time=1765139956628, experiment_id='504153010705164362', last_update_time=1765139956628, lifecycle_stage='active', name='Pokemon', tags={}>\n",
            "\n",
            "[1/10] Training model with params: {'n_estimators': 2, 'learning_rate': 0.053887843975205234, 'max_depth': 3, 'min_samples_split': 11}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2/10] Training model with params: {'n_estimators': 7, 'learning_rate': 0.07973680290593639, 'max_depth': 2, 'min_samples_split': 6}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3/10] Training model with params: {'n_estimators': 5, 'learning_rate': 0.0861139701990353, 'max_depth': 3, 'min_samples_split': 15}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4/10] Training model with params: {'n_estimators': 7, 'learning_rate': 0.02281136326755459, 'max_depth': 3, 'min_samples_split': 11}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5/10] Training model with params: {'n_estimators': 5, 'learning_rate': 0.10267649888486018, 'max_depth': 2, 'min_samples_split': 16}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6/10] Training model with params: {'n_estimators': 5, 'learning_rate': 0.092276161327083, 'max_depth': 3, 'min_samples_split': 11}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7/10] Training model with params: {'n_estimators': 3, 'learning_rate': 0.06545847870158349, 'max_depth': 2, 'min_samples_split': 18}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8/10] Training model with params: {'n_estimators': 2, 'learning_rate': 0.09276311719925821, 'max_depth': 2, 'min_samples_split': 14}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9/10] Training model with params: {'n_estimators': 2, 'learning_rate': 0.04545259681298684, 'max_depth': 3, 'min_samples_split': 6}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[10/10] Training model with params: {'n_estimators': 7, 'learning_rate': 0.09931211213221977, 'max_depth': 3, 'min_samples_split': 16}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "All experiments logged to ./mlruns/\n"
          ]
        },
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Set up MLflow\n",
        "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
        "mlflow.set_experiment('Pokemon')\n",
        "\n",
        "# Verify MLflow tracking\n",
        "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "print(f\"Experiment: {mlflow.get_experiment_by_name('Pokemon')}\\n\")\n",
        "\n",
        "# Run the expriments to find the best model\n",
        "EXPERIMENT_NAME = 'Pokemon'\n",
        "for i, params in enumerate(random_grid):\n",
        "    print(f\"[{i+1}/{len(random_grid)}] Training model with params: {params}\")\n",
        "    mlflow_pipeline(\n",
        "        features= X_train,\n",
        "        target= y_train,\n",
        "        random_seed= RANDOM_SEED,\n",
        "        run_name= f'run_{i + 1}',\n",
        "        experiment_name= EXPERIMENT_NAME,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "print(\"\\nAll experiments logged to ./mlruns/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment Results:\n",
            "   metrics.accuracy params.n_estimators  params.learning_rate params.max_depth params.min_samples_split\n",
            "0          0.933210                   7   0.09931211213221977                3                       16\n",
            "1          0.912801                   2   0.04545259681298684                3                        6\n",
            "2          0.846939                   2   0.09276311719925821                2                       14\n",
            "3          0.857143                   3   0.06545847870158349                2                       18\n",
            "4          0.916512                   5     0.092276161327083                3                       11\n",
            "5          0.880334                   5   0.10267649888486018                2                       16\n",
            "6          0.895176                   7   0.02281136326755459                3                       11\n",
            "7          0.916512                   5    0.0861139701990353                3                       15\n",
            "8          0.879406                   7   0.07973680290593639                2                        6\n",
            "9          0.912801                   2  0.053887843975205234                3                       11\n",
            "\n",
            "Best Model Parameters:\n",
            "run_id                                       72bc39cf86b14d86964e6c0ab6a32c64\n",
            "experiment_id                                              504153010705164362\n",
            "status                                                               FINISHED\n",
            "artifact_uri                file:///home/sagemaker-user/mlruns/50415301070...\n",
            "start_time                                   2025-12-07 20:39:54.965000+00:00\n",
            "end_time                                     2025-12-07 20:39:58.807000+00:00\n",
            "metrics.recall                                                        0.96475\n",
            "metrics.precision                                                    0.907504\n",
            "metrics.f1                                                           0.935252\n",
            "metrics.accuracy                                                      0.93321\n",
            "params.learning_rate                                      0.09931211213221977\n",
            "params.max_depth                                                            3\n",
            "params.min_samples_split                                                   16\n",
            "params.n_estimators                                                         7\n",
            "tags.mlflow.user                                               sagemaker-user\n",
            "tags.mlflow.source.name     /smus_kernel_server/.venv/lib/python3.11/site-...\n",
            "tags.mlflow.source.type                                                 LOCAL\n",
            "tags.mlflow.runName                                                    run_10\n",
            "Name: 102, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Get all runs from the MLflow experiments\n",
        "experiment = mlflow.get_experiment_by_name('Pokemon')\n",
        "runs = mlflow.search_runs(experiment_ids= [experiment.experiment_id])\n",
        "\n",
        "\n",
        "# Sort and print the restults\n",
        "print(\"Experiment Results:\")\n",
        "print(runs[[\n",
        "    'metrics.accuracy', \n",
        "    'params.n_estimators',\n",
        "    'params.learning_rate',\n",
        "    'params.max_depth',\n",
        "    'params.min_samples_split',\n",
        "]].head(10).to_string())\n",
        "\n",
        "# Show best run hyperparameters\n",
        "best_run = runs.sort_values('metrics.accuracy', ascending= False).iloc[0]\n",
        "print(\"\\nBest Model Parameters:\")\n",
        "print(best_run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploading best run 72bc39cf86b14d86964e6c0ab6a32c64 to s3://ml-ops-fp/MLflow/best-run/...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully uploaded 18 files to s3://ml-ops-fp/MLflow/best-run/\n"
          ]
        },
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Upload best MLflow run artifacts to S3\n",
        "upload_mlflow(best_run['run_id'], experiment.experiment_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As seen above, the best model is a gradient boosting model with 7 estimators, a max depth of 3, and a minimum of 16 samples to split. In addition to recoridng parameter sets tested, and logging performance metrics, we have also generated certain model diagnostic plots for each experiment that are related to our classification task. \n",
        "\n",
        "Below, we can see these diagnostic plots for our best run. Specifically, we can begin by looking at the confusion matrix:\n",
        "\n",
        "[![confusion matrix]()](https://raw.githubusercontent.com/bhstoller/ml-ops-fp/main/mlflow-images/confusion_matrix.png)\n",
        "\n",
        "As seen in the confusion matrix, we have high numbers of true positives and true negatives, the counts of which represent the SMOTE-augmented data used for model training. Overall, the model is clearly classifying the majority of characters correctly. Next, we can examine the feature importances:\n",
        "\n",
        "![feature importances](mlflow-images/feature_importance.png)\n",
        "\n",
        "As seen in the feature importance plots, predictions are most impacted by the special defense statistic (`Sp_Def`) of certain pokemon characters. `Generation`, `Attack`, `Height_m`, and `Type_2` are the next most important features. After these features, the remaining importances are relatively minimal. Next we can examine the precision-recall curve:\n",
        "\n",
        "![precision recall](mlflow-images/precision_recall.png)\n",
        "\n",
        "As seen in the precision-recall curve, the model is performing quite well against both precision and recall, with a good balance being found between the two. This indicates the model's predictions are fairly balanced and not skewed towards one or the other (eg always predicting that a character has a mega evolution). Lastly, we can examine the ROC curve:\n",
        "\n",
        "![roc curve](mlflow-images/roc_curve.png)\n",
        "\n",
        "As seen in the ROC curve, the area under the curve of 0.98 is quite high. This reflects the ability of the model to distinguish between pokemon which have and do not have mega evolutions.\n",
        "\n",
        "Overall, we can be very confident that this model is highly effective (headlined by the high accuracy of 93%), and can move forward with deploying it for inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5a. Convert the best MLflow model to a native XG-Boost model\n",
        "However, to deploy a XG-Boost model via AWS, the model must be a native XG-Boost model. Thus, we will use the exact hyperparameters from the best MLflow model above to create a native XG-Boost model via the `XGBoost` library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5a. Convert the best MLflow model to a native XG-Boost model\n",
        "To deploy via AWS, the model must be a native XG-Boost model Thus, we will use the exact hyperparameters from the best MLflow model to create a native XG-Boost model via the `XGBoost` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training XG-Boost model with the optimal hyperparameters...\n",
            "\n",
            "XG-Boost model trained\n",
            "- Accuracy: 0.8828\n"
          ]
        }
      ],
      "source": [
        "best_run = runs.sort_values('metrics.accuracy', ascending= False).iloc[0]\n",
        "\n",
        "# Extract hyperparameters\n",
        "best_params = {\n",
        "    'n_estimators': int(best_run['params.n_estimators']),\n",
        "    'learning_rate': float(best_run['params.learning_rate']),\n",
        "    'max_depth': int(best_run['params.max_depth']),\n",
        "    'min_samples_split': int(best_run['params.min_samples_split'])\n",
        "}\n",
        "\n",
        "# Map sklearn params to XGBoost params\n",
        "xgb_params = {\n",
        "    'n_estimators': best_params['n_estimators'],\n",
        "    'learning_rate': best_params['learning_rate'],\n",
        "    'max_depth': best_params['max_depth'],\n",
        "    'min_child_weight': best_params['min_samples_split'],\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss',\n",
        "    'use_label_encoder': False,\n",
        "    'random_state': RANDOM_SEED\n",
        "}\n",
        "\n",
        "print(\"Training XG-Boost model with the optimal hyperparameters...\")\n",
        "\n",
        "# Train XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(**xgb_params)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "xgb_accuracy = accuracy_score(y_test, y_pred)\n",
        "xgb_f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nXG-Boost model trained\")\n",
        "print(f\"- Accuracy: {xgb_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25a4c3d9",
      "metadata": {},
      "source": [
        "As we can see here, we are getting very similar performance to the MLflow best model, which is expected since we are using the same hyperparameters. Now that we have our native XG-Boost model, we can deploy it for inference via AWS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5b. Deploy the native XG-Boost model to AWS for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model packaged as model.tar.gz\n",
            "Model uploaded to: s3://ml-ops-fp/pokemon-data/pokemon.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Deploying model to SageMaker endpoint...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model already deployed\n",
            "- Endpoint name: pokemon-model\n",
            "- Model location: s3://ml-ops-fp/model/model.tar.gz\n",
            "- Instance type: ml.m5.large\n"
          ]
        },
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Set S3 configurations for model saving\n",
        "MODEL_KEY = 'model/model.tar.gz'\n",
        "MODEL_S3_PATH = f's3://{BUCKET_NAME}/{MODEL_KEY}'\n",
        "ENDPOINT_NAME = 'pokemon-model'\n",
        "\n",
        "# Save the model\n",
        "xgb_model.save_model('xgboost-model')\n",
        "\n",
        "# Convert to tar.gz format (SageMaker requirement)\n",
        "with tarfile.open('model.tar.gz', 'w:gz') as tar:\n",
        "    tar.add('xgboost-model')\n",
        "print(\"Model packaged as model.tar.gz\")\n",
        "\n",
        "# Upload to S3\n",
        "S3_CLIENT.upload_file(\n",
        "    Filename='model.tar.gz',\n",
        "    Bucket=BUCKET_NAME,\n",
        "    Key= MODEL_KEY\n",
        ")\n",
        "print(f\"Model uploaded to: {S3_PATH}\")\n",
        "\n",
        "xgb_model_sm = XGBoostModel(\n",
        "    model_data= MODEL_S3_PATH,\n",
        "    role= ROLE_ARN,\n",
        "    framework_version= '1.7-1',\n",
        "    sagemaker_session= SESSION\n",
        ")\n",
        "\n",
        "print(\"\\nDeploying model to SageMaker endpoint...\")\n",
        "\n",
        "# Deploy to endpoint\n",
        "try:\n",
        "    predictor = xgb_model_sm.deploy(\n",
        "        initial_instance_count= 1,\n",
        "        instance_type= 'ml.m5.large',\n",
        "        endpoint_name= ENDPOINT_NAME\n",
        "    )\n",
        "    print(\"\\nModel successfully deployed\")\n",
        "    print(f\"- Endpoint name: {ENDPOINT_NAME}\")\n",
        "    print(f\"- Model location: {MODEL_S3_PATH}\")\n",
        "    print(f\"- Instance type: ml.m5.large\")\n",
        "    \n",
        "except Exception as e:\n",
        "    if 'Cannot create already existing endpoint' in str(e) or 'already exists' in str(e):\n",
        "        print(f\"\\nModel already deployed\")\n",
        "        print(f\"- Endpoint name: {ENDPOINT_NAME}\")\n",
        "        print(f\"- Model location: {MODEL_S3_PATH}\")\n",
        "        print(f\"- Instance type: ml.m5.large\")\n",
        "    else:\n",
        "        raise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49eeb903",
      "metadata": {},
      "source": [
        "Now, by using `predictor` we can inference the model the way we normally would had it be defined in the notebook. However, the model is actually deployed in the cloud via a AWS endpoint (specifically `pokemon-model`). As such, now we can move forward with model monitoring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **6. Set up model monitoring (if there is a monitoring dashboard show that)**\n",
        "While trying to set up model monitoring via AWS, we encountered a known-limitation involving data type errors. As such, we recieved express permission from Professor Bose to use Evidently AI for model monitoring, and sync the drift reports to S3 to stay in our AWS ecosystem.\n",
        "\n",
        "For the baseline in our drift detection, we will use the training data (`X_train`) for data input drift detection. However, it is important to note that we are using the training data *before* SMOTE was applied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline data prepared:\n",
            "  - Shape: (576, 20)\n",
            "  - Features: 20\n",
            "  - Samples: 576\n",
            "\n",
            "Monitoring configuration complete\n",
            "  - Monitoring tool: Evidently AI\n",
            "  - Baseline: Original test dataset\n",
            "  - Drift detection enabled: True\n"
          ]
        }
      ],
      "source": [
        "# Prepare baseline data for drift comparison\n",
        "baseline_data = X_train_raw.copy()\n",
        "\n",
        "print(f\"Baseline data prepared:\")\n",
        "print(f\"  - Shape: {baseline_data.shape}\")\n",
        "print(f\"  - Features: {baseline_data.shape[1]}\")\n",
        "print(f\"  - Samples: {baseline_data.shape[0]}\")\n",
        "\n",
        "print(\"\\nMonitoring configuration complete\")\n",
        "print(\"  - Monitoring tool: Evidently AI\")\n",
        "print(\"  - Baseline: Original test dataset\")\n",
        "print(\"  - Drift detection enabled: True\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aa4ffe5",
      "metadata": {},
      "source": [
        "As we can see, we have now set up model monitoring via Evidently AI and AWS, and can now commence with inferencing the `X_test` data and monitoring drift."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **7. Use the test data with the deployed model and validate the results (metric) and model monitoring**\n",
        "First, we will inference the deployed model via the AWS endpoint. From this, we will obtain the predictions and accuracy (evaluation metric)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing model using test (X_test) data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results:\n",
            "- Accuracy: 0.883\n"
          ]
        },
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Connect to the model endpoint\n",
        "predictor = Predictor(\n",
        "    endpoint_name= ENDPOINT_NAME,\n",
        "    sagemaker_session= SESSION,\n",
        "    serializer= CSVSerializer(),\n",
        "    deserializer= CSVDeserializer()\n",
        ")\n",
        "\n",
        "print(\"Testing model using test (X_test) data...\")\n",
        "\n",
        "# Get predictions\n",
        "y_pred_original = []\n",
        "for i in range(len(X_test)):\n",
        "    sample = X_test.iloc[i:i+1].values  # Get sample values\n",
        "    pred = predictor.predict(sample)  # Get predictions from deployed model\n",
        "    pred_value = float(np.array(pred).flatten()[0])  # Flatten and convert to float\n",
        "    y_pred_original.append(1 if pred_value > 0.5 else 0)  # Convert to binary classification\n",
        "\n",
        "accuracy_original = accuracy_score(y_test, y_pred_original)\n",
        "\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"- Accuracy: {accuracy_original:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "031d9f27",
      "metadata": {},
      "source": [
        "As seen above, we were able to successfully inference the deployed model, with a very similar test accuracy (88.3) to the train accuracy (88.28). This speaks to our model's strong generalizability without over or underfitting. Now, we can monitor these results in context with Evidently AI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MODEL MONITORING: DRIFT DETECTION\n",
            "============================================================\n",
            "Generating baseline predictions from the deployed model...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Drift Detection Results:\n",
            "Total features analyzed: 21\n",
            "\n",
            "Test: Number of Drifted Features\n",
            "Status: SUCCESS\n",
            "Description: The drift is detected for 2 out of 21 features. The test threshold is lt=3.\n",
            "Parameters: {'condition': {'lt': 3}, 'features': {'prediction': {'stattest': 'Z-test p_value', 'score': 0.163, 'threshold': 0.05, 'detected': False}, 'Attack': {'stattest': 'K-S p_value', 'score': 0.466, 'threshold': 0.05, 'detected': False}, 'Body_Style': {'stattest': 'K-S p_value', 'score': 0.858, 'threshold': 0.05, 'detected': False}, 'Catch_Difficulty': {'stattest': 'chi-square p_value', 'score': 0.184, 'threshold': 0.05, 'detected': False}, 'Color': {'stattest': 'K-S p_value', 'score': 0.549, 'threshold': 0.05, 'detected': False}, 'Defense': {'stattest': 'K-S p_value', 'score': 0.056, 'threshold': 0.05, 'detected': False}, 'Egg_Group_1': {'stattest': 'K-S p_value', 'score': 0.999, 'threshold': 0.05, 'detected': False}, 'Egg_Group_2': {'stattest': 'K-S p_value', 'score': 0.545, 'threshold': 0.05, 'detected': False}, 'Generation': {'stattest': 'K-S p_value', 'score': 0.945, 'threshold': 0.05, 'detected': False}, 'HP': {'stattest': 'K-S p_value', 'score': 0.295, 'threshold': 0.05, 'detected': False}, 'Has_Egg_Group_2': {'stattest': 'Z-test p_value', 'score': 0.077, 'threshold': 0.05, 'detected': False}, 'Has_Type_2': {'stattest': 'Z-test p_value', 'score': 0.002, 'threshold': 0.05, 'detected': True}, 'Height_m': {'stattest': 'K-S p_value', 'score': 0.17, 'threshold': 0.05, 'detected': False}, 'Sp_Atk': {'stattest': 'K-S p_value', 'score': 0.468, 'threshold': 0.05, 'detected': False}, 'Sp_Def': {'stattest': 'K-S p_value', 'score': 0.08, 'threshold': 0.05, 'detected': False}, 'Speed': {'stattest': 'K-S p_value', 'score': 0.217, 'threshold': 0.05, 'detected': False}, 'Total': {'stattest': 'K-S p_value', 'score': 0.053, 'threshold': 0.05, 'detected': False}, 'Type_1': {'stattest': 'K-S p_value', 'score': 0.562, 'threshold': 0.05, 'detected': False}, 'Type_2': {'stattest': 'K-S p_value', 'score': 0.017, 'threshold': 0.05, 'detected': True}, 'Weight_kg': {'stattest': 'K-S p_value', 'score': 0.545, 'threshold': 0.05, 'detected': False}, 'isLegendary': {'stattest': 'Z-test p_value', 'score': 0.634, 'threshold': 0.05, 'detected': False}}}\n",
            "\n",
            "Report saved to s3://ml-ops-fp/reports/monitoring_report_original.html\n"
          ]
        },
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "REPORT_TYPE = 'original'\n",
        "REPORT_S3_PATH = f\"reports/monitoring_report_{REPORT_TYPE}.html\"\n",
        "\n",
        "# Monitor Model Predictions: X_test\n",
        "results_original = detect_model_drift(\n",
        "    test_data= X_test,\n",
        "    y_pred= y_pred_original,\n",
        "    report_s3_key= REPORT_S3_PATH,\n",
        "    predictor= predictor,\n",
        "    baseline_data= baseline_data,\n",
        "    bucket_name= BUCKET_NAME,\n",
        "    s3_client= S3_CLIENT\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92dedfa6",
      "metadata": {},
      "source": [
        "We can see the drift report findings above, and via the drift report that was uploaded to S3:\n",
        "![X_test Evidently Report](evidently-images/x_test_report.png)\n",
        "\n",
        "From the report, we see that there is no significant drift detected when inferencing the X_test. While two columns (`Type_2` and `Has_Type_2`) are detected as drift with X_test, this is not a reflection of actual drift in the data, rather it is a stratification issue between the train and test data. Specifically, for the feature `Type_2` there a large number of possible pokemon values, as such the balance of classes likely differs due to randomization in the creation of train and test.\n",
        "\n",
        "However, even just these two columns do not exceed the total threshold for data input drift existing, and the predictions p-value is 1.0, suggesting no drift at all in the accuracy. This is expected since the test data in `X_test` should not be materially different from `X_train` since they were comprise the same original data.\n",
        "\n",
        "Now we can change some of the columns in X_test and see if we observe drift from those changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **8. Change at least 2 feature values of the test dataset (you can put in random values or swap 2 features)**\n",
        "To change the data, we made four main modifications:\n",
        "1. Swapping column 0 and column 1\n",
        "2. Swapping column 2 and column 7\n",
        "3. Randomizing column 2\n",
        "4. Randomizing column 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modifying test data...\n",
            "Change 1: Swap column 0 and column 1\n",
            "Change 2: Swap column 2 and column 7\n",
            "Change 3: Randomizing column 2\n",
            "Change 4: Randomizing column 4\n",
            "Test data modified successfully\n",
            "\n",
            "Before and After Comparison: Row 0:\n",
            "Original: [ 6.         18.         -1.57698178 -1.10222852 -1.2190696  -1.06975269\n",
            "  0.02599269 -1.12151659 -1.71020758  2.        ]\n",
            "\n",
            "Modified: [ 1.80000000e+01  6.00000000e+00  1.01000000e+02 -1.10222852e+00\n",
            "  5.20000000e+01 -1.06975269e+00  2.59926897e-02 -1.57698178e+00\n",
            " -1.71020758e+00  2.00000000e+00]\n"
          ]
        }
      ],
      "source": [
        "print(\"Modifying test data...\")\n",
        "X_test_modified = X_test.copy()  # Create a copy for modification\n",
        "\n",
        "# Change 1\n",
        "print(\"Change 1: Swap column 0 and column 1\")\n",
        "X_test_modified.iloc[:, [0, 1]] = X_test_modified.iloc[:, [1, 0]].values\n",
        "\n",
        "# Change 2\n",
        "print(\"Change 2: Swap column 2 and column 7\")\n",
        "X_test_modified.iloc[:, [2, 7]] = X_test_modified.iloc[:, [7, 2]].values\n",
        "\n",
        "# Change 3\n",
        "print(\"Change 3: Randomizing column 2\")\n",
        "X_test_modified.iloc[:, 2] = np.random.randint(50, 150, size=len(X_test_modified))\n",
        "\n",
        "# Change 4\n",
        "print(\"Change 4: Randomizing column 4\")\n",
        "X_test_modified.iloc[:, 4] = np.random.randint(50, 150, size=len(X_test_modified))\n",
        "\n",
        "print(\"Test data modified successfully\")\n",
        "print(f\"\\nBefore and After Comparison: Row 0:\")\n",
        "print(f\"Original: {X_test.iloc[0, :10].values}\")\n",
        "print(f\"\\nModified: {X_test_modified.iloc[0, :10].values}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dcca71d",
      "metadata": {},
      "source": [
        "Now that we have modified X_test, we can inference `X_test_modified` to the deployed model and see if we detect drift, which we should since we changed the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **9. Use the \"changed\" test data with the deployed model and validate the results (metric) and verify observation with model monitoring.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing model using modified (X_test_modified) data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results:\n",
            "- Accuracy: 0.738\n"
          ]
        },
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Testing model using modified (X_test_modified) data...\")\n",
        "\n",
        "# Get predictions\n",
        "y_pred_modified = []\n",
        "for i in range(len(X_test_modified)):\n",
        "    sample = X_test_modified.iloc[i:i+1].values  # Get sample values\n",
        "    pred = predictor.predict(sample)  # Get predictions from deployed model\n",
        "    pred_value = float(np.array(pred).flatten()[0])  # Flatten and convert to float\n",
        "    y_pred_modified.append(1 if pred_value > 0.5 else 0)  # Convert to binary classification\n",
        "\n",
        "accuracy_modified = accuracy_score(y_test, y_pred_modified)\n",
        "\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"- Accuracy: {accuracy_modified:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02a3d493",
      "metadata": {},
      "source": [
        "As seen above, we were able to successfully inference the deployed model with `X_test_modified`, but this time with a much lower accuracy than with `X_test` or our `X_train`. Specifically, after changing the data, the new accuracy is 73.8%, which is lower than the test accuracy of 88.3% and the train accuracy of 88.3% as well. However, this is very expected since we made significant changes to the data. Now, we can monitor these results in context with Evidently AI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MODEL MONITORING: DRIFT DETECTION\n",
            "============================================================\n",
            "Generating baseline predictions from the deployed model...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Drift Detection Results:\n",
            "Total features analyzed: 21\n",
            "\n",
            "Test: Number of Drifted Features\n",
            "Status: FAIL\n",
            "Description: The drift is detected for 7 out of 21 features. The test threshold is lt=3.\n",
            "Parameters: {'condition': {'lt': 3}, 'features': {'prediction': {'stattest': 'Z-test p_value', 'score': 0.0, 'threshold': 0.05, 'detected': True}, 'Attack': {'stattest': 'K-S p_value', 'score': 0.0, 'threshold': 0.05, 'detected': True}, 'Body_Style': {'stattest': 'K-S p_value', 'score': 0.858, 'threshold': 0.05, 'detected': False}, 'Catch_Difficulty': {'stattest': 'chi-square p_value', 'score': 0.184, 'threshold': 0.05, 'detected': False}, 'Color': {'stattest': 'K-S p_value', 'score': 0.549, 'threshold': 0.05, 'detected': False}, 'Defense': {'stattest': 'K-S p_value', 'score': 0.056, 'threshold': 0.05, 'detected': False}, 'Egg_Group_1': {'stattest': 'K-S p_value', 'score': 0.999, 'threshold': 0.05, 'detected': False}, 'Egg_Group_2': {'stattest': 'K-S p_value', 'score': 0.545, 'threshold': 0.05, 'detected': False}, 'Generation': {'stattest': 'K-S p_value', 'score': 0.945, 'threshold': 0.05, 'detected': False}, 'HP': {'stattest': 'K-S p_value', 'score': 0.295, 'threshold': 0.05, 'detected': False}, 'Has_Egg_Group_2': {'stattest': 'Z-test p_value', 'score': 0.077, 'threshold': 0.05, 'detected': False}, 'Has_Type_2': {'stattest': 'Z-test p_value', 'score': 0.002, 'threshold': 0.05, 'detected': True}, 'Height_m': {'stattest': 'K-S p_value', 'score': 0.17, 'threshold': 0.05, 'detected': False}, 'Sp_Atk': {'stattest': 'K-S p_value', 'score': 0.468, 'threshold': 0.05, 'detected': False}, 'Sp_Def': {'stattest': 'K-S p_value', 'score': 0.005, 'threshold': 0.05, 'detected': True}, 'Speed': {'stattest': 'K-S p_value', 'score': 0.217, 'threshold': 0.05, 'detected': False}, 'Total': {'stattest': 'K-S p_value', 'score': 0.0, 'threshold': 0.05, 'detected': True}, 'Type_1': {'stattest': 'K-S p_value', 'score': 0.0, 'threshold': 0.05, 'detected': True}, 'Type_2': {'stattest': 'K-S p_value', 'score': 0.0, 'threshold': 0.05, 'detected': True}, 'Weight_kg': {'stattest': 'K-S p_value', 'score': 0.545, 'threshold': 0.05, 'detected': False}, 'isLegendary': {'stattest': 'Z-test p_value', 'score': 0.634, 'threshold': 0.05, 'detected': False}}}\n",
            "\n",
            "Report saved to s3://ml-ops-fp/reports/monitoring_report_modified.html\n"
          ]
        },
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "REPORT_TYPE = 'modified'\n",
        "REPORT_S3_PATH = f\"reports/monitoring_report_{REPORT_TYPE}.html\"\n",
        "\n",
        "# Monitor Model Predictions: X_test_modified\n",
        "results_original = detect_model_drift(\n",
        "    test_data= X_test_modified,\n",
        "    y_pred= y_pred_modified,\n",
        "    report_s3_key= REPORT_S3_PATH,\n",
        "    predictor= predictor,\n",
        "    baseline_data= baseline_data,\n",
        "    bucket_name= BUCKET_NAME,\n",
        "    s3_client= S3_CLIENT\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79d36870",
      "metadata": {},
      "source": [
        "We can see the drift report findings above, and via the drift report that was uploaded to S3:\n",
        "![X_test Evidently Report](evidently-images/x_test_modified_report.png)\n",
        "\n",
        "From the report, we now see that there is significant drift detected when inferencing the X_test, for seven columns (five new columns and the original two that were detected). Specifically, we see that the drift is detected in the exact columns that we swapped and randomized. Furthermore, the prediction drift p-value is now 0.0, confirming that now only the data input, but the prediction accuracy itself is significantly different than for the training. \n",
        "\n",
        "\n",
        "While these changes were obviously intentional, it underscores the importance of setting up proper model monitoring so that these types of issues can be detected as populations change over time, and predictions are made at times that are far from when the model was created."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
